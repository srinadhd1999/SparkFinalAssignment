2024.06.18 11:24:13 INFO  Started: Metals version 1.3.1 in folders '/private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment' for client Visual Studio Code 1.89.1.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@5e90b25f]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@c6ddbce]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@5e90b25f]
2024.06.18 11:24:14 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.06.18 11:24:16 INFO  running '/opt/homebrew/bin/sbt -Dbloop.export-jar-classifiers=sources bloopInstall'
2024.06.18 11:24:16 ERROR [info] [launcher] getting org.scala-sbt sbt 1.9.9  (this may take some time)...
2024.06.18 11:24:27 INFO  [info] welcome to sbt 1.9.9 (Homebrew Java 21.0.3)
2024.06.18 11:24:27 INFO  [info] loading settings for project sparkfinalassignment-build-build from metals.sbt ...
2024.06.18 11:24:28 INFO  no build target found for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/build.sbt. Using presentation compiler with project's scala-library version: 3.3.3
2024.06.18 11:24:28 INFO  [info] loading project definition from /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/project
2024.06.18 11:24:29 WARN  Could not find semantic tokens for: file:///private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/build.sbt
2024.06.18 11:24:28 INFO  [info] loading settings for project sparkfinalassignment-build from metals.sbt ...
2024.06.18 11:24:29 INFO  [info] loading project definition from /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project
2024.06.18 11:24:32 INFO  [success] Generated .bloop/sparkfinalassignment-build.json
2024.06.18 11:24:32 INFO  [success] Total time: 3 s, completed 18-Jun-2024, 11:24:32 am
2024.06.18 11:24:32 INFO  [info] loading settings for project sparkfinalassignment from build.sbt ...
2024.06.18 11:24:33 INFO  [info] set current project to hello-world (in build file:/private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/)
2024.06.18 11:24:33 INFO  [success] Generated .bloop/sparkfinalassignment.json
2024.06.18 11:24:33 INFO  [success] Generated .bloop/sparkfinalassignment-test.json
2024.06.18 11:24:33 INFO  [success] Total time: 1 s, completed 18-Jun-2024, 11:24:34 am
2024.06.18 11:24:34 INFO  time: ran 'sbt bloopInstall' in 17s
2024.06.18 11:24:34 INFO  Attempting to connect to the build server...
2024.06.18 11:24:34 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 11:24:37 INFO  Attempting to connect to the build server...
2024.06.18 11:24:37 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 11:24:38 INFO  time: Connected to build server in 4.33s
2024.06.18 11:24:38 INFO  Connected to Build server: Bloop v1.5.17
2024.06.18 11:24:50 INFO  time: indexed workspace in 12s
2024.06.18 11:25:25 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 11:25:27 INFO  time: compiled sparkfinalassignment in 1.93s
2024.06.18 11:32:33 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 11:32:33 INFO  time: compiled sparkfinalassignment in 0.29s
Jun 18, 2024 11:34:38 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 213
Jun 18, 2024 11:34:40 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 233
Jun 18, 2024 11:37:03 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 451
2024.06.18 11:37:07 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:1: error: can't use unescaped LF in character literals
import org.apache'
                  ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:390)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

Jun 18, 2024 11:39:10 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 996
2024.06.18 11:39:20 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 11:39:20 INFO  time: compiled sparkfinalassignment in 0.12s
2024.06.18 11:40:00 INFO  compiling sparkfinalassignment (2 scala sources)
2024.06.18 11:40:00 INFO  time: compiled sparkfinalassignment in 71ms
2024.06.18 11:40:05 WARN  Target root /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.bloop/sparkfinalassignment-build/bloop-bsp-clients-classes/classes-Metals-SFHkeMX9TcOPY_PpqX-kVA== does not exist
2024.06.18 11:40:05 INFO  compiling sparkfinalassignment (2 scala sources)
2024.06.18 11:40:05 INFO  time: compiled sparkfinalassignment in 84ms
2024.06.18 11:40:05 INFO  compiling sparkfinalassignment (2 scala sources)
2024.06.18 11:40:05 INFO  time: compiled sparkfinalassignment in 49ms
2024.06.18 11:40:09 WARN  Target root /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.bloop/sparkfinalassignment-build/bloop-bsp-clients-classes/classes-Metals-SFHkeMX9TcOPY_PpqX-kVA== does not exist
2024.06.18 11:40:16 INFO  compiling sparkfinalassignment (2 scala sources)
2024.06.18 11:40:16 INFO  time: compiled sparkfinalassignment in 67ms
2024.06.18 11:40:16 WARN  Target root /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.bloop/sparkfinalassignment/bloop-bsp-clients-classes/classes-Metals-1lmcKsTaRxifreLdO_gb7A== does not exist
2024.06.18 11:40:41 WARN  Target root /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.bloop/sparkfinalassignment-build/bloop-bsp-clients-classes/classes-Metals-SFHkeMX9TcOPY_PpqX-kVA== does not exist
2024.06.18 11:41:02 INFO  compiling sparkfinalassignment (2 scala sources)
2024.06.18 11:41:02 INFO  time: compiled sparkfinalassignment in 77ms
2024.06.18 11:41:02 WARN  Target root /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.bloop/sparkfinalassignment/bloop-bsp-clients-classes/classes-Metals-1lmcKsTaRxifreLdO_gb7A== does not exist
2024.06.18 11:41:09 WARN  Target root /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.bloop/sparkfinalassignment/bloop-bsp-clients-classes/classes-Metals-1lmcKsTaRxifreLdO_gb7A== does not exist
2024.06.18 11:41:10 WARN  Target root /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.bloop/sparkfinalassignment/bloop-bsp-clients-classes/classes-Metals-1lmcKsTaRxifreLdO_gb7A== does not exist
Jun 18, 2024 11:41:10 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1119
2024.06.18 11:41:10 WARN  Target root /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.bloop/sparkfinalassignment/bloop-bsp-clients-classes/classes-Metals-1lmcKsTaRxifreLdO_gb7A== does not exist
2024.06.18 11:41:11 WARN  Target root /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.bloop/sparkfinalassignment/bloop-bsp-clients-classes/classes-Metals-1lmcKsTaRxifreLdO_gb7A== does not exist
2024.06.18 11:41:13 WARN  Target root /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.bloop/sparkfinalassignment/bloop-bsp-clients-classes/classes-Metals-1lmcKsTaRxifreLdO_gb7A== does not exist
2024.06.18 11:41:15 INFO  compiling sparkfinalassignment (2 scala sources)
2024.06.18 11:41:15 INFO  time: compiled sparkfinalassignment in 62ms
2024.06.18 11:41:15 WARN  Target root /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.bloop/sparkfinalassignment/bloop-bsp-clients-classes/classes-Metals-1lmcKsTaRxifreLdO_gb7A== does not exist
2024.06.18 11:42:11 INFO  no build target found for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/metals.sbt. Using presentation compiler with project's scala-library version: 2.13.12
2024.06.18 11:42:11 INFO  no build target found for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/metals.sbt. Using presentation compiler with project's scala-library version: 2.13.12
2024.06.18 11:42:12 INFO  no build target found for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/metals.sbt. Using presentation compiler with project's scala-library version: 2.13.12
2024.06.18 11:42:20 WARN  Target root /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.bloop/sparkfinalassignment-build/bloop-bsp-clients-classes/classes-Metals-SFHkeMX9TcOPY_PpqX-kVA== does not exist
2024.06.18 11:42:21 INFO  no build target found for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/metals.sbt. Using presentation compiler with project's scala-library version: 2.13.12
2024.06.18 11:42:23 WARN  Target root /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.bloop/sparkfinalassignment-build/bloop-bsp-clients-classes/classes-Metals-SFHkeMX9TcOPY_PpqX-kVA== does not exist
2024.06.18 11:42:24 INFO  compiling sparkfinalassignment (2 scala sources)
2024.06.18 11:42:24 INFO  time: compiled sparkfinalassignment in 68ms
2024.06.18 11:42:24 WARN  Target root /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.bloop/sparkfinalassignment/bloop-bsp-clients-classes/classes-Metals-1lmcKsTaRxifreLdO_gb7A== does not exist
2024.06.18 11:43:12 WARN  Target root /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.bloop/sparkfinalassignment-build/bloop-bsp-clients-classes/classes-Metals-SFHkeMX9TcOPY_PpqX-kVA== does not exist
2024.06.18 11:43:13 WARN  Target root /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.bloop/sparkfinalassignment-build/bloop-bsp-clients-classes/classes-Metals-SFHkeMX9TcOPY_PpqX-kVA== does not exist
2024.06.18 11:43:20 WARN  Target root /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.bloop/sparkfinalassignment-build/bloop-bsp-clients-classes/classes-Metals-SFHkeMX9TcOPY_PpqX-kVA== does not exist
2024.06.18 11:43:21 INFO  compiling sparkfinalassignment (2 scala sources)
2024.06.18 11:43:21 INFO  time: compiled sparkfinalassignment in 64ms
2024.06.18 11:43:21 WARN  Target root /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.bloop/sparkfinalassignment/bloop-bsp-clients-classes/classes-Metals-1lmcKsTaRxifreLdO_gb7A== does not exist
2024.06.18 11:43:23 INFO  running '/opt/homebrew/bin/sbt -Dbloop.export-jar-classifiers=sources bloopInstall'
2024.06.18 11:43:23 WARN  Target root /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.bloop/sparkfinalassignment/bloop-bsp-clients-classes/classes-Metals-1lmcKsTaRxifreLdO_gb7A== does not exist
2024.06.18 11:43:29 INFO  [info] welcome to sbt 1.9.9 (Homebrew Java 21.0.3)
2024.06.18 11:43:29 INFO  [info] loading settings for project sparkfinalassignment-build-build from metals.sbt ...
2024.06.18 11:43:29 INFO  [info] loading project definition from /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/project
2024.06.18 11:43:29 INFO  [info] loading settings for project sparkfinalassignment-build from metals.sbt ...
2024.06.18 11:43:30 INFO  [info] loading project definition from /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project
2024.06.18 11:43:30 INFO  [success] Generated .bloop/sparkfinalassignment-build.json
2024.06.18 11:43:30 INFO  [success] Total time: 1 s, completed 18-Jun-2024, 11:43:30 am
2024.06.18 11:43:32 INFO  [info] loading settings for project sparkfinalassignment from build.sbt ...
2024.06.18 11:43:32 INFO  [info] set current project to sparkfinalassignment (in build file:/private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/)
2024.06.18 11:43:33 INFO  [success] Generated .bloop/sparkfinalassignment.json
2024.06.18 11:43:33 INFO  [success] Generated .bloop/sparkfinalassignment-test.json
2024.06.18 11:43:33 INFO  [success] Total time: 1 s, completed 18-Jun-2024, 11:43:33 am
2024.06.18 11:43:33 INFO  time: ran 'sbt bloopInstall' in 10s
2024.06.18 11:43:33 INFO  Disconnecting from Bloop session...
2024.06.18 11:43:33 INFO  Shut down connection with build server.
2024.06.18 11:43:33 INFO  Shut down connection with build server.
2024.06.18 11:43:33 INFO  Attempting to connect to the build server...
2024.06.18 11:43:33 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 11:43:33 INFO  Attempting to connect to the build server...
2024.06.18 11:43:33 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 11:43:33 INFO  time: Connected to build server in 57ms
2024.06.18 11:43:33 INFO  Connected to Build server: Bloop v1.5.17
2024.06.18 11:43:42 INFO  time: indexed workspace in 9.36s
2024.06.18 11:43:43 INFO  compiling sparkfinalassignment (2 scala sources)
2024.06.18 11:43:43 INFO  time: compiled sparkfinalassignment in 0.84s
2024.06.18 11:44:05 INFO  compiling sparkfinalassignment (2 scala sources)
2024.06.18 11:44:05 INFO  time: compiled sparkfinalassignment in 0.16s
2024.06.18 11:44:50 INFO  compiling sparkfinalassignment (2 scala sources)
2024.06.18 11:44:51 INFO  time: compiled sparkfinalassignment in 1.12s
2024.06.18 11:45:33 INFO  compiling sparkfinalassignment (2 scala sources)
2024.06.18 11:45:33 INFO  time: compiled sparkfinalassignment in 0.51s
2024.06.18 11:45:39 WARN  Target root /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.bloop/sparkfinalassignment-build/bloop-bsp-clients-classes/classes-Metals-q8TIcXYVRVOwixjDEMKbFQ== does not exist
2024.06.18 11:45:45 WARN  Target root /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.bloop/sparkfinalassignment-build/bloop-bsp-clients-classes/classes-Metals-q8TIcXYVRVOwixjDEMKbFQ== does not exist
2024.06.18 11:45:46 WARN  Target root /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.bloop/sparkfinalassignment-build/bloop-bsp-clients-classes/classes-Metals-q8TIcXYVRVOwixjDEMKbFQ== does not exist
2024.06.18 11:45:47 WARN  Target root /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.bloop/sparkfinalassignment-build/bloop-bsp-clients-classes/classes-Metals-q8TIcXYVRVOwixjDEMKbFQ== does not exist
2024.06.18 11:45:48 WARN  Target root /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.bloop/sparkfinalassignment-build/bloop-bsp-clients-classes/classes-Metals-q8TIcXYVRVOwixjDEMKbFQ== does not exist
2024.06.18 11:45:49 WARN  Target root /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.bloop/sparkfinalassignment-build/bloop-bsp-clients-classes/classes-Metals-q8TIcXYVRVOwixjDEMKbFQ== does not exist
2024.06.18 11:45:54 WARN  Target root /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.bloop/sparkfinalassignment-build/bloop-bsp-clients-classes/classes-Metals-q8TIcXYVRVOwixjDEMKbFQ== does not exist
2024.06.18 11:45:59 WARN  Target root /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.bloop/sparkfinalassignment-build/bloop-bsp-clients-classes/classes-Metals-q8TIcXYVRVOwixjDEMKbFQ== does not exist
2024.06.18 11:46:01 WARN  Target root /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.bloop/sparkfinalassignment-build/bloop-bsp-clients-classes/classes-Metals-q8TIcXYVRVOwixjDEMKbFQ== does not exist
2024.06.18 11:46:03 WARN  Target root /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.bloop/sparkfinalassignment-build/bloop-bsp-clients-classes/classes-Metals-q8TIcXYVRVOwixjDEMKbFQ== does not exist
2024.06.18 11:46:04 WARN  Target root /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.bloop/sparkfinalassignment-build/bloop-bsp-clients-classes/classes-Metals-q8TIcXYVRVOwixjDEMKbFQ== does not exist
2024.06.18 11:46:11 INFO  running '/opt/homebrew/bin/sbt -Dbloop.export-jar-classifiers=sources bloopInstall'
2024.06.18 11:46:11 WARN  Target root /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.bloop/sparkfinalassignment-build/bloop-bsp-clients-classes/classes-Metals-q8TIcXYVRVOwixjDEMKbFQ== does not exist
2024.06.18 11:46:17 INFO  [info] welcome to sbt 1.9.9 (Homebrew Java 21.0.3)
2024.06.18 11:46:17 INFO  [info] loading settings for project sparkfinalassignment-build-build from metals.sbt ...
2024.06.18 11:46:17 INFO  [info] loading project definition from /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/project
2024.06.18 11:46:17 INFO  [info] loading settings for project sparkfinalassignment-build from metals.sbt ...
2024.06.18 11:46:18 INFO  [info] loading project definition from /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project
2024.06.18 11:46:18 INFO  [success] Generated .bloop/sparkfinalassignment-build.json
2024.06.18 11:46:18 INFO  [success] Total time: 1 s, completed 18-Jun-2024, 11:46:19 am
2024.06.18 11:46:20 INFO  [info] loading settings for project sparkfinalassignment from build.sbt ...
2024.06.18 11:46:20 INFO  [info] set current project to sparkfinalassignment (in build file:/private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/)
2024.06.18 11:46:30 INFO  [success] Generated .bloop/sparkfinalassignment-test.json
2024.06.18 11:46:30 INFO  [success] Generated .bloop/sparkfinalassignment.json
2024.06.18 11:46:30 INFO  [success] Total time: 10 s, completed 18-Jun-2024, 11:46:30 am
2024.06.18 11:46:30 INFO  time: ran 'sbt bloopInstall' in 18s
2024.06.18 11:46:30 INFO  Disconnecting from Bloop session...
2024.06.18 11:46:30 INFO  Shut down connection with build server.
2024.06.18 11:46:30 INFO  Shut down connection with build server.
2024.06.18 11:46:30 INFO  Attempting to connect to the build server...
2024.06.18 11:46:30 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 11:46:30 INFO  Attempting to connect to the build server...
2024.06.18 11:46:30 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 11:46:30 INFO  time: Connected to build server in 48ms
2024.06.18 11:46:30 INFO  Connected to Build server: Bloop v1.5.17
2024.06.18 11:46:34 INFO  time: indexed workspace in 4.39s
2024.06.18 11:46:35 INFO  compiling sparkfinalassignment (2 scala sources)
2024.06.18 11:46:35 INFO  time: compiled sparkfinalassignment in 0.61s
Jun 18, 2024 11:59:03 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.metals/.reports/metals-full/2024-06-18/r_compiler-error_(sparkfinalassignment-build)_11-59-03-418.md
2024.06.18 12:15:55 INFO  running '/opt/homebrew/bin/sbt -Dbloop.export-jar-classifiers=sources bloopInstall'
2024.06.18 12:16:01 INFO  [info] welcome to sbt 1.9.9 (Homebrew Java 21.0.3)
2024.06.18 12:16:01 INFO  [info] loading settings for project sparkfinalassignment-build-build from metals.sbt ...
2024.06.18 12:16:01 INFO  [info] loading project definition from /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/project
2024.06.18 12:16:01 INFO  [info] loading settings for project sparkfinalassignment-build from metals.sbt ...
2024.06.18 12:16:02 INFO  [info] loading project definition from /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project
2024.06.18 12:16:02 INFO  [success] Generated .bloop/sparkfinalassignment-build.json
2024.06.18 12:16:02 INFO  [success] Total time: 1 s, completed 18-Jun-2024, 12:16:03 pm
2024.06.18 12:16:05 INFO  [info] loading settings for project sparkfinalassignment from build.sbt ...
2024.06.18 12:16:05 INFO  [info] set current project to LogAnalysis (in build file:/private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/)
2024.06.18 12:16:05 INFO  [warn] there's a key that's not used by any other settings/tasks:
2024.06.18 12:16:05 INFO  [warn]  
2024.06.18 12:16:05 INFO  [warn] * sparkfinalassignment / Compile / compile / classLoaderLayeringStrategy
2024.06.18 12:16:05 INFO  [warn]   +- /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/build.sbt:20
2024.06.18 12:16:05 INFO  [warn]  
2024.06.18 12:16:05 INFO  [warn] note: a setting might still be used by a command; to exclude a key from this `lintUnused` check
2024.06.18 12:16:05 INFO  [warn] either append it to `Global / excludeLintKeys` or call .withRank(KeyRanks.Invisible) on the key
2024.06.18 12:16:07 INFO  [success] Generated .bloop/sparkfinalassignment.json
2024.06.18 12:16:07 INFO  [success] Generated .bloop/sparkfinalassignment-test.json
2024.06.18 12:16:07 INFO  [success] Total time: 2 s, completed 18-Jun-2024, 12:16:07 pm
2024.06.18 12:16:07 INFO  time: ran 'sbt bloopInstall' in 12s
2024.06.18 12:16:07 INFO  Disconnecting from Bloop session...
2024.06.18 12:16:07 INFO  Shut down connection with build server.
2024.06.18 12:16:07 INFO  Shut down connection with build server.
2024.06.18 12:16:07 INFO  Attempting to connect to the build server...
2024.06.18 12:16:12 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 12:16:12 INFO  Attempting to connect to the build server...
2024.06.18 12:16:12 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 12:16:12 INFO  time: Connected to build server in 4.99s
2024.06.18 12:16:12 INFO  Connected to Build server: Bloop v1.5.17
2024.06.18 12:16:12 WARN  2.12.10 is no longer supported in the current Metals versions, using the last known supported version 0.11.12
2024.06.18 12:16:24 INFO  time: indexed workspace in 12s
2024.06.18 12:16:24 INFO  compiling sparkfinalassignment (2 scala sources)
2024.06.18 12:16:24 INFO  time: compiled sparkfinalassignment in 0.58s
Jun 18, 2024 12:16:25 PM scala.meta.internal.pc.CompilerAccess retryWithCleanCompiler
INFO: compiler crashed due to an error in the Scala compiler, retrying with new compiler instance.
Jun 18, 2024 12:16:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: 
  bad constant pool index: 0 at pos: 48461
     while compiling: <no file>
        during phase: globalPhase=<no phase>, enteringPhase=<some phase>
     library version: version 2.12.10
    compiler version: version 2.12.10
  reconstructed args: -classpath /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.bloop/sparkfinalassignment/bloop-bsp-clients-classes/classes-Metals-LSEg-OC7Tym0I4Xs0sIJFQ==:/Users/srinadh/Library/Caches/bloop/semanticdb/com.sourcegraph.semanticdb-javac.0.9.10/semanticdb-javac-0.9.10.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-core_2.12/3.1.2/spark-core_2.12-3.1.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-sql_2.12/3.1.2/spark-sql_2.12-3.1.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/twitter/chill_2.12/0.9.5/chill_2.12-0.9.5.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/twitter/chill-java/0.9.5/chill-java-0.9.5.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/xbean/xbean-asm7-shaded/4.15/xbean-asm7-shaded-4.15.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-client/3.2.0/hadoop-client-3.2.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-launcher_2.12/3.1.2/spark-launcher_2.12-3.1.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-kvstore_2.12/3.1.2/spark-kvstore_2.12-3.1.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-network-common_2.12/3.1.2/spark-network-common_2.12-3.1.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-network-shuffle_2.12/3.1.2/spark-network-shuffle_2.12-3.1.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.1.2/spark-unsafe_2.12-3.1.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/javax/activation/activation/1.1.1/activation-1.1.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/curator/curator-recipes/2.13.0/curator-recipes-2.13.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/zookeeper/zookeeper/3.4.14/zookeeper-3.4.14.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/jakarta/servlet/jakarta.servlet-api/4.0.3/jakarta.servlet-api-4.0.3.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/commons/commons-lang3/3.10/commons-lang3-3.10.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/commons/commons-math3/3.4.1/commons-math3-3.4.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/commons/commons-text/1.6/commons-text-1.6.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/slf4j/jul-to-slf4j/1.7.30/jul-to-slf4j-1.7.30.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/slf4j/jcl-over-slf4j/1.7.30/jcl-over-slf4j-1.7.30.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/log4j/log4j/1.2.17/log4j-1.2.17.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/slf4j/slf4j-log4j12/1.7.30/slf4j-log4j12-1.7.30.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.1.8.2/snappy-java-1.1.8.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/github/luben/zstd-jni/1.4.8-1/zstd-jni-1.4.8-1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/roaringbitmap/RoaringBitmap/0.9.0/RoaringBitmap-0.9.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/commons-net/commons-net/3.6/commons-net-3.6.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/modules/scala-xml_2.12/1.2.0/scala-xml_2.12-1.2.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/scala-reflect/2.12.10/scala-reflect-2.12.10.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/json4s/json4s-jackson_2.12/3.7.0-M5/json4s-jackson_2.12-3.7.0-M5.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/core/jersey-client/2.30/jersey-client-2.30.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/core/jersey-common/2.30/jersey-common-2.30.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/core/jersey-server/2.30/jersey-server-2.30.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/containers/jersey-container-servlet/2.30/jersey-container-servlet-2.30.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/containers/jersey-container-servlet-core/2.30/jersey-container-servlet-core-2.30.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/inject/jersey-hk2/2.30/jersey-hk2-2.30.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/netty/netty-all/4.1.51.Final/netty-all-4.1.51.Final.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/clearspring/analytics/stream/2.9.6/stream-2.9.6.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/dropwizard/metrics/metrics-core/4.1.1/metrics-core-4.1.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/dropwizard/metrics/metrics-jvm/4.1.1/metrics-jvm-4.1.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/dropwizard/metrics/metrics-json/4.1.1/metrics-json-4.1.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/dropwizard/metrics/metrics-graphite/4.1.1/metrics-graphite-4.1.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/dropwizard/metrics/metrics-jmx/4.1.1/metrics-jmx-4.1.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-databind/2.10.0/jackson-databind-2.10.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.10.0/jackson-module-scala_2.12-2.10.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/oro/oro/2.0.8/oro-2.0.8.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/net/razorvine/pyrolite/4.30/pyrolite-4.30.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/net/sf/py4j/py4j/0.10.9/py4j-0.10.9.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-tags_2.12/3.1.2/spark-tags_2.12-3.1.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/commons/commons-crypto/1.1.0/commons-crypto-1.1.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/univocity/univocity-parsers/2.9.1/univocity-parsers-2.9.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-sketch_2.12/3.1.2/spark-sketch_2.12-3.1.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-catalyst_2.12/3.1.2/spark-catalyst_2.12-3.1.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/orc/orc-core/1.5.12/orc-core-1.5.12.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/orc/orc-mapreduce/1.5.12/orc-mapreduce-1.5.12.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hive/hive-storage-api/2.7.2/hive-storage-api-2.7.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-column/1.10.1/parquet-column-1.10.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-hadoop/1.10.1/parquet-hadoop-1.10.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/commons/commons-compress/1.8.1/commons-compress-1.8.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/tukaani/xz/1.5/xz-1.5.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/esotericsoftware/kryo-shaded/4.0.2/kryo-shaded-4.0.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-hdfs-client/3.2.0/hadoop-hdfs-client-3.2.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-api/3.2.0/hadoop-yarn-api-3.2.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-client/3.2.0/hadoop-yarn-client-3.2.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-core/3.2.0/hadoop-mapreduce-client-core-3.2.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.2.0/hadoop-mapreduce-client-jobclient-3.2.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-annotations/3.2.0/hadoop-annotations-3.2.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-core/2.10.0/jackson-core-2.10.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-annotations/2.10.0/jackson-annotations-2.10.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/curator/curator-framework/2.13.0/curator-framework-2.13.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/roaringbitmap/shims/0.9.0/shims-0.9.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/json4s/json4s-core_2.12/3.7.0-M5/json4s-core_2.12-3.7.0-M5.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/jakarta/ws/rs/jakarta.ws.rs-api/2.1.6/jakarta.ws.rs-api-2.1.6.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/hk2/external/jakarta.inject/2.6.1/jakarta.inject-2.6.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/jakarta/annotation/jakarta.annotation-api/1.3.5/jakarta.annotation-api-1.3.5.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/hk2/osgi-resource-locator/1.0.3/osgi-resource-locator-1.0.3.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/media/jersey-media-jaxb/2.30/jersey-media-jaxb-2.30.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/jakarta/validation/jakarta.validation-api/2.0.2/jakarta.validation-api-2.0.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/hk2/hk2-locator/2.6.1/hk2-locator-2.6.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/javassist/javassist/3.25.0-GA/javassist-3.25.0-GA.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/fasterxml/jackson/module/jackson-module-paranamer/2.10.0/jackson-module-paranamer-2.10.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/modules/scala-parser-combinators_2.12/1.1.2/scala-parser-combinators_2.12-1.1.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/codehaus/janino/janino/3.0.16/janino-3.0.16.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/codehaus/janino/commons-compiler/3.0.16/commons-compiler-3.0.16.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/antlr/antlr4-runtime/4.8-1/antlr4-runtime-4.8-1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/arrow/arrow-vector/2.0.0/arrow-vector-2.0.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/arrow/arrow-memory-netty/2.0.0/arrow-memory-netty-2.0.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/orc/orc-shims/1.5.12/orc-shims-1.5.12.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/airlift/aircompressor/0.10/aircompressor-0.10.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-common/1.10.1/parquet-common-1.10.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-encoding/1.10.1/parquet-encoding-1.10.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-format/2.4.0/parquet-format-2.4.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-jackson/1.10.1/parquet-jackson-1.10.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/esotericsoftware/minlog/1.3.0/minlog-1.3.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/objenesis/objenesis/2.5.1/objenesis-2.5.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/google/guava/guava/16.0.1/guava-16.0.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/commons-io/commons-io/2.5/commons-io-2.5.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/eclipse/jetty/jetty-servlet/9.3.24.v20180605/jetty-servlet-9.3.24.v20180605.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/commons-beanutils/commons-beanutils/1.9.3/commons-beanutils-1.9.3.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/google/re2j/re2j/1.1/re2j-1.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-auth/3.2.0/hadoop-auth-3.2.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/curator/curator-client/2.13.0/curator-client-2.13.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-common/3.2.0/hadoop-yarn-common-3.2.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-common/3.2.0/hadoop-mapreduce-client-common-3.2.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/json4s/json4s-ast_2.12/3.7.0-M5/json4s-ast_2.12-3.7.0-M5.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/json4s/json4s-scalap_2.12/3.7.0-M5/json4s-scalap_2.12-3.7.0-M5.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/sun/activation/jakarta.activation/1.2.1/jakarta.activation-1.2.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/hk2/external/aopalliance-repackaged/2.6.1/aopalliance-repackaged-2.6.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/hk2/hk2-api/2.6.1/hk2-api-2.6.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/hk2/hk2-utils/2.6.1/hk2-utils-2.6.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/arrow/arrow-format/2.0.0/arrow-format-2.0.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/arrow/arrow-memory-core/2.0.0/arrow-memory-core-2.0.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/eclipse/jetty/jetty-security/9.3.24.v20180605/jetty-security-9.3.24.v20180605.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/net/minidev/json-smart/2.3/json-smart-2.3.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/eclipse/jetty/jetty-util/9.3.24.v20180605/jetty-util-9.3.24.v20180605.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.9.5/jackson-module-jaxb-annotations-2.9.5.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.9.5/jackson-jaxrs-json-provider-2.9.5.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.9.5/jackson-jaxrs-base-2.9.5.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/google/inject/guice/4.0/guice-4.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/github/spotbugs/spotbugs-annotations/3.1.9/spotbugs-annotations-3.1.9.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/javax/inject/javax.inject/1/javax.inject-1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/jline/jline/0.9.94/jline-0.9.94.jar -Xplugin-require:semanticdb -Yrangepos -Ymacro-expand:discard -Ycache-plugin-class-loader:last-modified -Ypresentation-any-thread

  last tree to typer: EmptyTree
       tree position: <unknown>
            tree tpe: <notype>
              symbol: null
           call site: <none> in <none>

== Source file context for tree position ==


scala.reflect.internal.FatalError: 
  bad constant pool index: 0 at pos: 48461
     while compiling: <no file>
        during phase: globalPhase=<no phase>, enteringPhase=<some phase>
     library version: version 2.12.10
    compiler version: version 2.12.10
  reconstructed args: -classpath /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.bloop/sparkfinalassignment/bloop-bsp-clients-classes/classes-Metals-LSEg-OC7Tym0I4Xs0sIJFQ==:/Users/srinadh/Library/Caches/bloop/semanticdb/com.sourcegraph.semanticdb-javac.0.9.10/semanticdb-javac-0.9.10.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/scala-library/2.12.10/scala-library-2.12.10.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-core_2.12/3.1.2/spark-core_2.12-3.1.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-sql_2.12/3.1.2/spark-sql_2.12-3.1.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/avro/avro/1.8.2/avro-1.8.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/twitter/chill_2.12/0.9.5/chill_2.12-0.9.5.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/twitter/chill-java/0.9.5/chill-java-0.9.5.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/xbean/xbean-asm7-shaded/4.15/xbean-asm7-shaded-4.15.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-client/3.2.0/hadoop-client-3.2.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-launcher_2.12/3.1.2/spark-launcher_2.12-3.1.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-kvstore_2.12/3.1.2/spark-kvstore_2.12-3.1.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-network-common_2.12/3.1.2/spark-network-common_2.12-3.1.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-network-shuffle_2.12/3.1.2/spark-network-shuffle_2.12-3.1.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.1.2/spark-unsafe_2.12-3.1.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/javax/activation/activation/1.1.1/activation-1.1.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/curator/curator-recipes/2.13.0/curator-recipes-2.13.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/zookeeper/zookeeper/3.4.14/zookeeper-3.4.14.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/jakarta/servlet/jakarta.servlet-api/4.0.3/jakarta.servlet-api-4.0.3.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/commons/commons-lang3/3.10/commons-lang3-3.10.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/commons/commons-math3/3.4.1/commons-math3-3.4.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/commons/commons-text/1.6/commons-text-1.6.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/slf4j/jul-to-slf4j/1.7.30/jul-to-slf4j-1.7.30.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/slf4j/jcl-over-slf4j/1.7.30/jcl-over-slf4j-1.7.30.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/log4j/log4j/1.2.17/log4j-1.2.17.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/slf4j/slf4j-log4j12/1.7.30/slf4j-log4j12-1.7.30.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.1.8.2/snappy-java-1.1.8.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/github/luben/zstd-jni/1.4.8-1/zstd-jni-1.4.8-1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/roaringbitmap/RoaringBitmap/0.9.0/RoaringBitmap-0.9.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/commons-net/commons-net/3.6/commons-net-3.6.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/modules/scala-xml_2.12/1.2.0/scala-xml_2.12-1.2.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/scala-reflect/2.12.10/scala-reflect-2.12.10.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/json4s/json4s-jackson_2.12/3.7.0-M5/json4s-jackson_2.12-3.7.0-M5.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/core/jersey-client/2.30/jersey-client-2.30.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/core/jersey-common/2.30/jersey-common-2.30.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/core/jersey-server/2.30/jersey-server-2.30.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/containers/jersey-container-servlet/2.30/jersey-container-servlet-2.30.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/containers/jersey-container-servlet-core/2.30/jersey-container-servlet-core-2.30.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/inject/jersey-hk2/2.30/jersey-hk2-2.30.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/netty/netty-all/4.1.51.Final/netty-all-4.1.51.Final.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/clearspring/analytics/stream/2.9.6/stream-2.9.6.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/dropwizard/metrics/metrics-core/4.1.1/metrics-core-4.1.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/dropwizard/metrics/metrics-jvm/4.1.1/metrics-jvm-4.1.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/dropwizard/metrics/metrics-json/4.1.1/metrics-json-4.1.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/dropwizard/metrics/metrics-graphite/4.1.1/metrics-graphite-4.1.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/dropwizard/metrics/metrics-jmx/4.1.1/metrics-jmx-4.1.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-databind/2.10.0/jackson-databind-2.10.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.10.0/jackson-module-scala_2.12-2.10.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/oro/oro/2.0.8/oro-2.0.8.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/net/razorvine/pyrolite/4.30/pyrolite-4.30.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/net/sf/py4j/py4j/0.10.9/py4j-0.10.9.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-tags_2.12/3.1.2/spark-tags_2.12-3.1.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/commons/commons-crypto/1.1.0/commons-crypto-1.1.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/univocity/univocity-parsers/2.9.1/univocity-parsers-2.9.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-sketch_2.12/3.1.2/spark-sketch_2.12-3.1.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-catalyst_2.12/3.1.2/spark-catalyst_2.12-3.1.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/orc/orc-core/1.5.12/orc-core-1.5.12.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/orc/orc-mapreduce/1.5.12/orc-mapreduce-1.5.12.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hive/hive-storage-api/2.7.2/hive-storage-api-2.7.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-column/1.10.1/parquet-column-1.10.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-hadoop/1.10.1/parquet-hadoop-1.10.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/commons/commons-compress/1.8.1/commons-compress-1.8.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/tukaani/xz/1.5/xz-1.5.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/esotericsoftware/kryo-shaded/4.0.2/kryo-shaded-4.0.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-hdfs-client/3.2.0/hadoop-hdfs-client-3.2.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-api/3.2.0/hadoop-yarn-api-3.2.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-client/3.2.0/hadoop-yarn-client-3.2.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-core/3.2.0/hadoop-mapreduce-client-core-3.2.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.2.0/hadoop-mapreduce-client-jobclient-3.2.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-annotations/3.2.0/hadoop-annotations-3.2.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-core/2.10.0/jackson-core-2.10.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-annotations/2.10.0/jackson-annotations-2.10.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/curator/curator-framework/2.13.0/curator-framework-2.13.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/roaringbitmap/shims/0.9.0/shims-0.9.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/json4s/json4s-core_2.12/3.7.0-M5/json4s-core_2.12-3.7.0-M5.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/jakarta/ws/rs/jakarta.ws.rs-api/2.1.6/jakarta.ws.rs-api-2.1.6.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/hk2/external/jakarta.inject/2.6.1/jakarta.inject-2.6.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/jakarta/annotation/jakarta.annotation-api/1.3.5/jakarta.annotation-api-1.3.5.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/hk2/osgi-resource-locator/1.0.3/osgi-resource-locator-1.0.3.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/media/jersey-media-jaxb/2.30/jersey-media-jaxb-2.30.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/jakarta/validation/jakarta.validation-api/2.0.2/jakarta.validation-api-2.0.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/hk2/hk2-locator/2.6.1/hk2-locator-2.6.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/javassist/javassist/3.25.0-GA/javassist-3.25.0-GA.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/fasterxml/jackson/module/jackson-module-paranamer/2.10.0/jackson-module-paranamer-2.10.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/modules/scala-parser-combinators_2.12/1.1.2/scala-parser-combinators_2.12-1.1.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/codehaus/janino/janino/3.0.16/janino-3.0.16.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/codehaus/janino/commons-compiler/3.0.16/commons-compiler-3.0.16.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/antlr/antlr4-runtime/4.8-1/antlr4-runtime-4.8-1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/arrow/arrow-vector/2.0.0/arrow-vector-2.0.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/arrow/arrow-memory-netty/2.0.0/arrow-memory-netty-2.0.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/orc/orc-shims/1.5.12/orc-shims-1.5.12.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/airlift/aircompressor/0.10/aircompressor-0.10.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-common/1.10.1/parquet-common-1.10.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-encoding/1.10.1/parquet-encoding-1.10.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-format/2.4.0/parquet-format-2.4.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-jackson/1.10.1/parquet-jackson-1.10.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/esotericsoftware/minlog/1.3.0/minlog-1.3.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/objenesis/objenesis/2.5.1/objenesis-2.5.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/google/guava/guava/16.0.1/guava-16.0.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/httpcomponents/httpclient/4.5.2/httpclient-4.5.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/commons-io/commons-io/2.5/commons-io-2.5.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/eclipse/jetty/jetty-servlet/9.3.24.v20180605/jetty-servlet-9.3.24.v20180605.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/commons-beanutils/commons-beanutils/1.9.3/commons-beanutils-1.9.3.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/google/re2j/re2j/1.1/re2j-1.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-auth/3.2.0/hadoop-auth-3.2.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/curator/curator-client/2.13.0/curator-client-2.13.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/codehaus/woodstox/stax2-api/3.1.4/stax2-api-3.1.4.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/fasterxml/woodstox/woodstox-core/5.0.3/woodstox-core-5.0.3.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-common/3.2.0/hadoop-yarn-common-3.2.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-common/3.2.0/hadoop-mapreduce-client-common-3.2.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/json4s/json4s-ast_2.12/3.7.0-M5/json4s-ast_2.12-3.7.0-M5.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/json4s/json4s-scalap_2.12/3.7.0-M5/json4s-scalap_2.12-3.7.0-M5.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/sun/activation/jakarta.activation/1.2.1/jakarta.activation-1.2.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/hk2/external/aopalliance-repackaged/2.6.1/aopalliance-repackaged-2.6.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/hk2/hk2-api/2.6.1/hk2-api-2.6.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/glassfish/hk2/hk2-utils/2.6.1/hk2-utils-2.6.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/arrow/arrow-format/2.0.0/arrow-format-2.0.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/arrow/arrow-memory-core/2.0.0/arrow-memory-core-2.0.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/eclipse/jetty/jetty-security/9.3.24.v20180605/jetty-security-9.3.24.v20180605.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/nimbusds/nimbus-jose-jwt/4.41.1/nimbus-jose-jwt-4.41.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/net/minidev/json-smart/2.3/json-smart-2.3.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/eclipse/jetty/jetty-util/9.3.24.v20180605/jetty-util-9.3.24.v20180605.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.9.5/jackson-module-jaxb-annotations-2.9.5.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.9.5/jackson-jaxrs-json-provider-2.9.5.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.9.5/jackson-jaxrs-base-2.9.5.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/google/inject/guice/4.0/guice-4.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/com/github/spotbugs/spotbugs-annotations/3.1.9/spotbugs-annotations-3.1.9.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/javax/inject/javax.inject/1/javax.inject-1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/Users/srinadh/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/jline/jline/0.9.94/jline-0.9.94.jar -Xplugin-require:semanticdb -Yrangepos -Ymacro-expand:discard -Ycache-plugin-class-loader:last-modified -Ypresentation-any-thread

  last tree to typer: EmptyTree
       tree position: <unknown>
            tree tpe: <notype>
              symbol: null
           call site: <none> in <none>

== Source file context for tree position ==


	at scala.reflect.internal.Reporting.abort(Reporting.scala:68)
	at scala.reflect.internal.Reporting.abort$(Reporting.scala:64)
	at scala.reflect.internal.SymbolTable.abort(SymbolTable.scala:28)
	at scala.tools.nsc.symtab.classfile.ClassfileParser$ConstantPool.errorBadIndex(ClassfileParser.scala:384)
	at scala.tools.nsc.symtab.classfile.ClassfileParser$ConstantPool.getExternalName(ClassfileParser.scala:248)
	at scala.tools.nsc.symtab.classfile.ClassfileParser.readParamNames$1(ClassfileParser.scala:838)
	at scala.tools.nsc.symtab.classfile.ClassfileParser.parseAttribute$1(ClassfileParser.scala:844)
	at scala.tools.nsc.symtab.classfile.ClassfileParser.$anonfun$parseAttributes$7(ClassfileParser.scala:911)
	at scala.tools.nsc.symtab.classfile.ClassfileParser.parseAttributes(ClassfileParser.scala:911)
	at scala.tools.nsc.symtab.classfile.ClassfileParser.parseMethod(ClassfileParser.scala:620)
	at scala.tools.nsc.symtab.classfile.ClassfileParser.$anonfun$parseClass$4(ClassfileParser.scala:533)
	at scala.tools.nsc.symtab.classfile.ClassfileParser.parseClass(ClassfileParser.scala:533)
	at scala.tools.nsc.symtab.classfile.ClassfileParser.$anonfun$parse$2(ClassfileParser.scala:161)
	at scala.tools.nsc.symtab.classfile.ClassfileParser.$anonfun$parse$1(ClassfileParser.scala:146)
	at scala.tools.nsc.symtab.classfile.ClassfileParser.parse(ClassfileParser.scala:129)
	at scala.tools.nsc.symtab.SymbolLoaders$ClassfileLoader.doComplete(SymbolLoaders.scala:329)
	at scala.tools.nsc.symtab.SymbolLoaders$SymbolLoader.complete(SymbolLoaders.scala:230)
	at scala.reflect.internal.Symbols$Symbol.info(Symbols.scala:1542)
	at scala.reflect.internal.Definitions.scala$reflect$internal$Definitions$$enterNewMethod(Definitions.scala:50)
	at scala.reflect.internal.Definitions$DefinitionsClass.String_$plus$lzycompute(Definitions.scala:1128)
	at scala.reflect.internal.Definitions$DefinitionsClass.String_$plus(Definitions.scala:1128)
	at scala.reflect.internal.Definitions$DefinitionsClass.syntheticCoreMethods$lzycompute(Definitions.scala:1414)
	at scala.reflect.internal.Definitions$DefinitionsClass.syntheticCoreMethods(Definitions.scala:1396)
	at scala.reflect.internal.Definitions$DefinitionsClass.symbolsNotPresentInBytecode$lzycompute(Definitions.scala:1426)
	at scala.reflect.internal.Definitions$DefinitionsClass.symbolsNotPresentInBytecode(Definitions.scala:1426)
	at scala.reflect.internal.Definitions$DefinitionsClass.init(Definitions.scala:1482)
	at scala.tools.nsc.Global$Run.<init>(Global.scala:1199)
	at scala.tools.nsc.interactive.Global$TyperRun.<init>(Global.scala:1322)
	at scala.tools.nsc.interactive.Global.newTyperRun(Global.scala:1345)
	at scala.tools.nsc.interactive.Global.<init>(Global.scala:294)
	at scala.meta.internal.pc.MetalsGlobal.<init>(MetalsGlobal.scala:40)

2024.06.18 12:16:42 INFO  running '/opt/homebrew/bin/sbt -Dbloop.export-jar-classifiers=sources bloopInstall'
2024.06.18 12:16:48 INFO  [info] welcome to sbt 1.9.9 (Homebrew Java 21.0.3)
2024.06.18 12:16:48 INFO  [info] loading settings for project sparkfinalassignment-build-build from metals.sbt ...
2024.06.18 12:16:48 INFO  [info] loading project definition from /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/project
2024.06.18 12:16:48 INFO  [info] loading settings for project sparkfinalassignment-build from metals.sbt ...
2024.06.18 12:16:49 INFO  [info] loading project definition from /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project
2024.06.18 12:16:49 INFO  [success] Generated .bloop/sparkfinalassignment-build.json
2024.06.18 12:16:49 INFO  [success] Total time: 1 s, completed 18-Jun-2024, 12:16:50 pm
2024.06.18 12:16:50 INFO  [info] loading settings for project sparkfinalassignment from build.sbt ...
2024.06.18 12:16:50 INFO  [info] set current project to LogAnalysis (in build file:/private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/)
2024.06.18 12:16:50 INFO  [warn] there's a key that's not used by any other settings/tasks:
2024.06.18 12:16:50 INFO  [warn]  
2024.06.18 12:16:50 INFO  [warn] * sparkfinalassignment / Compile / compile / classLoaderLayeringStrategy
2024.06.18 12:16:50 INFO  [warn]   +- /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/build.sbt:20
2024.06.18 12:16:50 INFO  [warn]  
2024.06.18 12:16:50 INFO  [warn] note: a setting might still be used by a command; to exclude a key from this `lintUnused` check
2024.06.18 12:16:50 INFO  [warn] either append it to `Global / excludeLintKeys` or call .withRank(KeyRanks.Invisible) on the key
2024.06.18 12:16:53 INFO  [success] Generated .bloop/sparkfinalassignment-test.json
2024.06.18 12:16:53 INFO  [success] Generated .bloop/sparkfinalassignment.json
2024.06.18 12:16:53 INFO  [success] Total time: 3 s, completed 18-Jun-2024, 12:16:53 pm
2024.06.18 12:16:53 INFO  time: ran 'sbt bloopInstall' in 11s
2024.06.18 12:16:53 INFO  Disconnecting from Bloop session...
2024.06.18 12:16:53 INFO  Shut down connection with build server.
2024.06.18 12:16:53 INFO  Shut down connection with build server.
2024.06.18 12:16:53 INFO  Attempting to connect to the build server...
2024.06.18 12:16:53 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 12:16:53 INFO  Attempting to connect to the build server...
2024.06.18 12:16:53 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 12:16:53 INFO  time: Connected to build server in 54ms
2024.06.18 12:16:53 INFO  Connected to Build server: Bloop v1.5.17
2024.06.18 12:16:57 INFO  time: indexed workspace in 3.47s
2024.06.18 12:16:57 INFO  compiling sparkfinalassignment (2 scala sources)
2024.06.18 12:17:05 INFO  time: compiled sparkfinalassignment in 7.77s
Jun 18, 2024 12:17:09 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1668
2024.06.18 12:20:29 INFO  running '/opt/homebrew/bin/sbt -Dbloop.export-jar-classifiers=sources bloopInstall'
2024.06.18 12:20:35 INFO  [info] welcome to sbt 1.9.9 (Homebrew Java 21.0.3)
2024.06.18 12:20:35 INFO  [info] loading settings for project sparkfinalassignment-build-build from metals.sbt ...
2024.06.18 12:20:35 INFO  [info] loading project definition from /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/project
2024.06.18 12:20:35 INFO  [info] loading settings for project sparkfinalassignment-build from metals.sbt ...
2024.06.18 12:20:36 INFO  [info] loading project definition from /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project
2024.06.18 12:20:36 INFO  [success] Generated .bloop/sparkfinalassignment-build.json
2024.06.18 12:20:36 INFO  [success] Total time: 1 s, completed 18-Jun-2024, 12:20:37 pm
2024.06.18 12:20:38 INFO  [info] loading settings for project sparkfinalassignment from build.sbt ...
2024.06.18 12:20:38 INFO  [info] set current project to LogAnalysis (in build file:/private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/)
2024.06.18 12:20:38 INFO  [warn] there's a key that's not used by any other settings/tasks:
2024.06.18 12:20:38 INFO  [warn]  
2024.06.18 12:20:38 INFO  [warn] * sparkfinalassignment / Compile / compile / classLoaderLayeringStrategy
2024.06.18 12:20:38 INFO  [warn]   +- /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/build.sbt:22
2024.06.18 12:20:38 INFO  [warn]  
2024.06.18 12:20:38 INFO  [warn] note: a setting might still be used by a command; to exclude a key from this `lintUnused` check
2024.06.18 12:20:38 INFO  [warn] either append it to `Global / excludeLintKeys` or call .withRank(KeyRanks.Invisible) on the key
2024.06.18 12:20:41 INFO  [success] Generated .bloop/sparkfinalassignment.json
2024.06.18 12:20:41 INFO  [success] Generated .bloop/sparkfinalassignment-test.json
2024.06.18 12:20:41 INFO  [success] Total time: 3 s, completed 18-Jun-2024, 12:20:41 pm
2024.06.18 12:20:41 INFO  time: ran 'sbt bloopInstall' in 11s
2024.06.18 12:20:41 INFO  Disconnecting from Bloop session...
2024.06.18 12:20:41 INFO  Shut down connection with build server.
2024.06.18 12:20:41 INFO  Shut down connection with build server.
2024.06.18 12:20:41 INFO  Attempting to connect to the build server...
2024.06.18 12:20:41 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 12:20:41 INFO  Attempting to connect to the build server...
2024.06.18 12:20:41 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 12:20:41 INFO  time: Connected to build server in 52ms
2024.06.18 12:20:41 INFO  Connected to Build server: Bloop v1.5.17
2024.06.18 12:20:45 INFO  time: indexed workspace in 3.79s
2024.06.18 12:20:45 INFO  compiling sparkfinalassignment (2 scala sources)
2024.06.18 12:20:45 INFO  time: compiled sparkfinalassignment in 0.68s
2024.06.18 12:24:55 INFO  running '/opt/homebrew/bin/sbt -Dbloop.export-jar-classifiers=sources bloopInstall'
2024.06.18 12:25:01 INFO  [info] welcome to sbt 1.9.9 (Homebrew Java 21.0.3)
2024.06.18 12:25:01 INFO  [info] loading settings for project sparkfinalassignment-build-build from metals.sbt ...
2024.06.18 12:25:01 INFO  [info] loading project definition from /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/project
2024.06.18 12:25:01 INFO  [info] loading settings for project sparkfinalassignment-build from metals.sbt ...
2024.06.18 12:25:01 INFO  [info] loading project definition from /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project
2024.06.18 12:25:03 INFO  [success] Generated .bloop/sparkfinalassignment-build.json
2024.06.18 12:25:03 INFO  [success] Total time: 1 s, completed 18-Jun-2024, 12:25:03 pm
2024.06.18 12:25:03 INFO  [info] loading settings for project sparkfinalassignment from build.sbt ...
2024.06.18 12:25:03 INFO  [info] set current project to LogAnalysis (in build file:/private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/)
2024.06.18 12:25:03 INFO  [success] Generated .bloop/sparkfinalassignment-test.json
2024.06.18 12:25:03 INFO  [success] Generated .bloop/sparkfinalassignment.json
2024.06.18 12:25:03 INFO  [success] Total time: 1 s, completed 18-Jun-2024, 12:25:04 pm
2024.06.18 12:25:04 INFO  time: ran 'sbt bloopInstall' in 8.54s
2024.06.18 12:25:04 INFO  Disconnecting from Bloop session...
2024.06.18 12:25:04 INFO  Shut down connection with build server.
2024.06.18 12:25:04 INFO  Shut down connection with build server.
2024.06.18 12:25:04 INFO  Attempting to connect to the build server...
2024.06.18 12:25:04 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 12:25:04 INFO  Attempting to connect to the build server...
2024.06.18 12:25:04 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 12:25:04 INFO  time: Connected to build server in 51ms
2024.06.18 12:25:04 INFO  Connected to Build server: Bloop v1.5.17
2024.06.18 12:25:07 INFO  time: indexed workspace in 3.52s
2024.06.18 12:30:52 INFO  Shutting down server
2024.06.18 12:30:52 INFO  shutting down Metals
2024.06.18 12:30:52 INFO  Shut down connection with build server.
2024.06.18 12:30:52 INFO  Shut down connection with build server.
2024.06.18 12:30:52 INFO  Exiting server
2024.06.18 12:31:30 INFO  Started: Metals version 1.3.1 in folders '/private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment' for client Visual Studio Code 1.89.1.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@7be67944]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@a0eecac]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@7be67944]
2024.06.18 12:31:30 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.06.18 12:31:31 INFO  Attempting to connect to the build server...
2024.06.18 12:31:31 INFO  no build target found for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/build.sbt. Using presentation compiler with project's scala-library version: 3.3.3
2024.06.18 12:31:31 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 12:31:31 INFO  Attempting to connect to the build server...
2024.06.18 12:31:31 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 12:31:31 INFO  time: Connected to build server in 0.27s
2024.06.18 12:31:31 INFO  Connected to Build server: Bloop v1.5.17
2024.06.18 12:31:41 INFO  time: indexed workspace in 9.56s
2024.06.18 12:31:42 INFO  time: code lens generation in 1.26s
2024.06.18 12:31:42 INFO  time: code lens generation in 1.26s
2024.06.18 12:33:03 INFO  running '/opt/homebrew/bin/sbt -Dbloop.export-jar-classifiers=sources bloopInstall'
2024.06.18 12:33:09 INFO  [info] welcome to sbt 1.9.9 (Eclipse Adoptium Java 11.0.23)
2024.06.18 12:33:09 INFO  [info] loading settings for project sparkfinalassignment-build-build from metals.sbt ...
2024.06.18 12:33:09 INFO  [info] loading project definition from /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/project
2024.06.18 12:33:11 INFO  [info] loading settings for project sparkfinalassignment-build from metals.sbt ...
2024.06.18 12:33:11 INFO  [info] loading project definition from /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project
2024.06.18 12:33:11 INFO  [success] Generated .bloop/sparkfinalassignment-build.json
2024.06.18 12:33:11 INFO  [success] Total time: 1 s, completed 18-Jun-2024, 12:33:12 PM
2024.06.18 12:33:12 ERROR /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/build.sbt:14: warning: method in in trait ScopingSetting is deprecated (since 1.5.0): `in` is deprecated; migrate to slash syntax - https://www.scala-sbt.org/1.x/docs/Migrating-from-sbt-013x.html#slash
2024.06.18 12:33:12 ERROR fork in run := true
2024.06.18 12:33:12 ERROR      ^
2024.06.18 12:33:13 INFO  [info] loading settings for project sparkfinalassignment from build.sbt ...
2024.06.18 12:33:13 INFO  [info] set current project to LogAnalysis (in build file:/private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/)
2024.06.18 12:33:15 INFO  [success] Generated .bloop/sparkfinalassignment.json
2024.06.18 12:33:15 INFO  [success] Generated .bloop/sparkfinalassignment-test.json
2024.06.18 12:33:15 INFO  [success] Total time: 2 s, completed 18-Jun-2024, 12:33:15 PM
2024.06.18 12:33:15 INFO  time: ran 'sbt bloopInstall' in 11s
2024.06.18 12:33:15 INFO  Disconnecting from Bloop session...
2024.06.18 12:33:15 INFO  Shut down connection with build server.
2024.06.18 12:33:15 INFO  Shut down connection with build server.
2024.06.18 12:33:15 INFO  Attempting to connect to the build server...
2024.06.18 12:33:15 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 12:33:15 INFO  Attempting to connect to the build server...
2024.06.18 12:33:15 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 12:33:15 INFO  time: Connected to build server in 52ms
2024.06.18 12:33:15 INFO  Connected to Build server: Bloop v1.5.17
2024.06.18 12:33:19 INFO  time: indexed workspace in 3.6s
2024.06.18 12:34:46 INFO  compiling sparkfinalassignment (2 scala sources)
2024.06.18 12:34:46 INFO  time: compiled sparkfinalassignment in 0.71s
2024.06.18 12:35:56 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 12:35:56 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.06.18 12:35:56 INFO  no build target found for /var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/Main.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.06.18 12:35:56 INFO  time: compiled sparkfinalassignment in 0.61s
Jun 18, 2024 12:39:57 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 213
2024.06.18 12:40:02 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 12:40:02 INFO  time: compiled sparkfinalassignment in 0.44s
2024.06.18 12:42:38 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:18: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:42:41 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:18: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:42:41 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:18: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:42:43 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:18: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:42:43 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:18: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:42:44 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:18: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:42:52 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:18: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:42:57 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:18: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:42:58 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:18: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:42:58 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:18: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:42:58 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:18: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:43:01 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:20: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:43:01 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:21: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:43:02 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:26: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:43:07 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:26: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:43:09 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:26: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:43:11 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:26: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:43:13 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:26: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:43:14 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:26: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:43:15 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:26: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:43:16 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:26: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:43:19 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:26: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:43:20 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:26: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:43:20 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:26: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:43:21 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:26: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:43:23 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:26: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:43:23 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:26: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:43:24 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:26: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:43:24 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:26: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:43:26 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:26: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:43:26 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:26: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:43:27 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:26: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:43:29 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 12:43:29 INFO  time: compiled sparkfinalassignment in 0.14s
2024.06.18 12:43:29 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:26: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:43:47 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:26: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:43:47 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:26: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:43:50 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:26: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:43:51 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:26: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:43:52 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:26: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:43:52 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:26: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:43:53 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:26: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:43:56 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:26: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:43:58 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:27: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:43:58 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:27: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:44:25 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:20: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 12:44:25 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:19: error: unclosed character literal
    log_pattern = re.compile(r'(\S+) (\S+) (\S+) \[(.*?)\] "(.*?)" (\d{3}) (\d+|-)')
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

Jun 18, 2024 12:45:01 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 871
2024.06.18 12:45:10 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 12:45:10 INFO  time: compiled sparkfinalassignment in 0.55s
2024.06.18 12:45:50 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 12:45:50 INFO  time: compiled sparkfinalassignment in 0.15s
2024.06.18 12:46:35 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 12:46:35 INFO  time: compiled sparkfinalassignment in 0.19s
2024.06.18 12:46:56 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 12:46:56 INFO  time: compiled sparkfinalassignment in 0.85s
2024.06.18 12:47:50 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 12:47:50 INFO  time: compiled sparkfinalassignment in 0.28s
2024.06.18 12:48:31 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 12:48:31 INFO  time: compiled sparkfinalassignment in 0.67s
Jun 18, 2024 12:49:18 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1742
2024.06.18 12:49:21 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 12:49:21 INFO  time: compiled sparkfinalassignment in 0.71s
2024.06.18 12:53:08 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 12:53:08 INFO  time: compiled sparkfinalassignment in 0.69s
2024.06.18 12:55:03 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 12:55:03 INFO  time: compiled sparkfinalassignment in 0.24s
2024.06.18 12:55:46 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 12:55:46 INFO  time: compiled sparkfinalassignment in 0.27s
2024.06.18 12:56:23 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 12:56:24 INFO  time: compiled sparkfinalassignment in 1.19s
2024.06.18 12:57:02 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 12:57:03 INFO  time: compiled sparkfinalassignment in 1.17s
Jun 18, 2024 1:54:19 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2703
2024.06.18 13:54:25 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 13:54:25 INFO  time: compiled sparkfinalassignment in 0.25s
2024.06.18 13:54:35 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 13:54:35 INFO  time: compiled sparkfinalassignment in 0.22s
2024.06.18 13:54:49 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 13:54:49 INFO  time: compiled sparkfinalassignment in 0.21s
2024.06.18 13:55:15 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 13:55:15 INFO  time: compiled sparkfinalassignment in 0.19s
2024.06.18 13:56:11 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 13:56:11 INFO  time: compiled sparkfinalassignment in 0.27s
2024.06.18 13:56:11 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 13:56:11 INFO  time: compiled sparkfinalassignment in 0.12s
2024.06.18 13:58:29 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 13:58:29 INFO  time: compiled sparkfinalassignment in 0.85s
2024.06.18 13:59:18 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 13:59:18 INFO  time: compiled sparkfinalassignment in 0.35s
2024.06.18 14:00:35 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:00:35 INFO  time: compiled sparkfinalassignment in 0.95s
2024.06.18 14:02:18 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:02:18 INFO  time: compiled sparkfinalassignment in 0.33s
2024.06.18 14:02:45 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:02:45 INFO  time: compiled sparkfinalassignment in 0.78s
Jun 18, 2024 2:03:29 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3571
2024.06.18 14:03:31 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:03:31 INFO  time: compiled sparkfinalassignment in 0.66s
2024.06.18 14:03:47 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:03:47 INFO  time: compiled sparkfinalassignment in 0.55s
Jun 18, 2024 2:04:36 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3677
2024.06.18 14:05:06 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:05:06 INFO  time: compiled sparkfinalassignment in 0.46s
Jun 18, 2024 2:06:50 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.metals/.reports/metals-full/2024-06-18/r_compiler-error_(sparkfinalassignment-build)_14-06-50-237.md
Jun 18, 2024 2:06:51 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.metals/.reports/metals-full/2024-06-18/r_compiler-error_(sparkfinalassignment-build)_14-06-51-484.md
2024.06.18 14:06:54 INFO  running '/opt/homebrew/bin/sbt -Dbloop.export-jar-classifiers=sources bloopInstall'
2024.06.18 14:07:01 INFO  [info] welcome to sbt 1.9.9 (Eclipse Adoptium Java 11.0.23)
2024.06.18 14:07:01 INFO  [info] loading settings for project sparkfinalassignment-build-build from metals.sbt ...
2024.06.18 14:07:01 INFO  [info] loading project definition from /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/project
2024.06.18 14:07:02 INFO  [info] loading settings for project sparkfinalassignment-build from metals.sbt ...
2024.06.18 14:07:02 INFO  [info] loading project definition from /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project
2024.06.18 14:07:03 INFO  [success] Generated .bloop/sparkfinalassignment-build.json
2024.06.18 14:07:03 INFO  [success] Total time: 1 s, completed 18-Jun-2024, 2:07:03 PM
2024.06.18 14:07:03 INFO  [error] [/private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/build.sbt]:20: ')' expected but string literal found.
2024.06.18 14:07:03 INFO  [warn] Project loading failed: (r)etry, (q)uit, (l)ast, or (i)gnore? (default: r)
2024.06.18 14:07:03 INFO  time: ran 'sbt bloopInstall' in 9.23s
2024.06.18 14:07:03 ERROR sbt command failed: /opt/homebrew/bin/sbt -Dbloop.export-jar-classifiers=sources bloopInstall
2024.06.18 14:07:03 INFO  Disconnecting from Bloop session...
2024.06.18 14:07:03 INFO  Shut down connection with build server.
2024.06.18 14:07:03 INFO  Shut down connection with build server.
2024.06.18 14:07:03 INFO  Attempting to connect to the build server...
2024.06.18 14:07:03 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 14:07:03 INFO  Attempting to connect to the build server...
2024.06.18 14:07:03 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 14:07:03 INFO  time: Connected to build server in 65ms
2024.06.18 14:07:03 INFO  Connected to Build server: Bloop v1.5.17
Jun 18, 2024 2:07:06 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.metals/.reports/metals-full/2024-06-18/r_compiler-error_(sparkfinalassignment-build)_14-07-06-433.md
2024.06.18 14:07:07 INFO  time: indexed workspace in 3.63s
2024.06.18 14:07:07 INFO  skipping build import with status 'Installed'
2024.06.18 14:07:07 INFO  Disconnecting from Bloop session...
2024.06.18 14:07:07 INFO  Shut down connection with build server.
2024.06.18 14:07:07 INFO  Shut down connection with build server.
Jun 18, 2024 2:07:07 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint notify
INFO: Failed to send notification message.
org.eclipse.lsp4j.jsonrpc.JsonRpcException: java.nio.channels.AsynchronousCloseException
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:72)
	at scala.meta.internal.metals.RequestMonitorImpl$$anon$1.consume(ServerLivenessMonitor.scala:41)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.notify(RemoteEndpoint.java:126)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.sendCancelNotification(RemoteEndpoint.java:180)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint$1.cancel(RemoteEndpoint.java:150)
	at scala.meta.internal.metals.utils.FutureWithTimeout$$anon$1.$anonfun$cancel$1(FutureWithTimeout.scala:37)
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17)
	at scala.util.Try$.apply(Try.scala:217)
	at scala.meta.internal.metals.utils.FutureWithTimeout$$anon$1.cancel(FutureWithTimeout.scala:37)
	at scala.meta.internal.metals.Cancelable$.$anonfun$cancelAll$1(Cancelable.scala:29)
	at scala.collection.immutable.List.foreach(List.scala:334)
	at scala.meta.internal.metals.Cancelable$.cancelAll(Cancelable.scala:28)
	at scala.meta.internal.metals.MutableCancelable.cancel(MutableCancelable.scala:25)
	at scala.meta.internal.metals.utils.RequestRegistry.cancel(RequestRegistry.scala:94)
	at scala.meta.internal.metals.BuildServerConnection.cancel(BuildServerConnection.scala:447)
	at scala.meta.internal.metals.BuildServerConnection.$anonfun$shutdown$1(BuildServerConnection.scala:179)
	at scala.meta.internal.metals.BuildServerConnection.$anonfun$shutdown$1$adapted(BuildServerConnection.scala:171)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.nio.channels.AsynchronousCloseException
	at java.base/java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)
	at java.base/sun.nio.ch.SinkChannelImpl.endWrite(SinkChannelImpl.java:263)
	at java.base/sun.nio.ch.SinkChannelImpl.write(SinkChannelImpl.java:285)
	at java.base/java.nio.channels.Channels.writeFullyImpl(Channels.java:74)
	at java.base/java.nio.channels.Channels.writeFully(Channels.java:93)
	at java.base/java.nio.channels.Channels$1.write(Channels.java:171)
	at java.base/java.io.OutputStream.write(OutputStream.java:127)
	at java.base/java.nio.channels.Channels$1.write(Channels.java:151)
	at scala.meta.internal.metals.ClosableOutputStream.write(ClosableOutputStream.scala:26)
	at java.base/java.io.FilterOutputStream.write(FilterOutputStream.java:137)
	at java.base/java.io.FilterOutputStream.write(FilterOutputStream.java:108)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:67)
	... 20 more

2024.06.18 14:07:07 INFO  Attempting to connect to the build server...
2024.06.18 14:07:07 INFO  Scala test classes not supported by server
2024.06.18 14:07:07 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 14:07:07 INFO  Attempting to connect to the build server...
2024.06.18 14:07:07 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 14:07:07 INFO  time: Connected to build server in 37ms
2024.06.18 14:07:07 INFO  Connected to Build server: Bloop v1.5.17
Jun 18, 2024 2:07:07 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.metals/.reports/metals-full/2024-06-18/r_compiler-error_(sparkfinalassignment-build)_14-07-07-905.md
2024.06.18 14:07:11 INFO  time: indexed workspace in 3.49s
2024.06.18 14:07:11 INFO  skipping build import with status 'Installed'
2024.06.18 14:07:11 INFO  Disconnecting from Bloop session...
2024.06.18 14:07:11 INFO  Shut down connection with build server.
2024.06.18 14:07:11 INFO  Shut down connection with build server.
Jun 18, 2024 2:07:11 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint notify
INFO: Failed to send notification message.
org.eclipse.lsp4j.jsonrpc.JsonRpcException: java.nio.channels.AsynchronousCloseException
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:72)
	at scala.meta.internal.metals.RequestMonitorImpl$$anon$1.consume(ServerLivenessMonitor.scala:41)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.notify(RemoteEndpoint.java:126)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.sendCancelNotification(RemoteEndpoint.java:180)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint$1.cancel(RemoteEndpoint.java:150)
	at scala.meta.internal.metals.utils.FutureWithTimeout$$anon$1.$anonfun$cancel$1(FutureWithTimeout.scala:37)
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17)
	at scala.util.Try$.apply(Try.scala:217)
	at scala.meta.internal.metals.utils.FutureWithTimeout$$anon$1.cancel(FutureWithTimeout.scala:37)
	at scala.meta.internal.metals.Cancelable$.$anonfun$cancelAll$1(Cancelable.scala:29)
	at scala.collection.immutable.List.foreach(List.scala:334)
	at scala.meta.internal.metals.Cancelable$.cancelAll(Cancelable.scala:28)
	at scala.meta.internal.metals.MutableCancelable.cancel(MutableCancelable.scala:25)
	at scala.meta.internal.metals.utils.RequestRegistry.cancel(RequestRegistry.scala:94)
	at scala.meta.internal.metals.BuildServerConnection.cancel(BuildServerConnection.scala:447)
	at scala.meta.internal.metals.BuildServerConnection.$anonfun$shutdown$1(BuildServerConnection.scala:179)
	at scala.meta.internal.metals.BuildServerConnection.$anonfun$shutdown$1$adapted(BuildServerConnection.scala:171)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.nio.channels.AsynchronousCloseException
	at java.base/java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)
	at java.base/sun.nio.ch.SinkChannelImpl.endWrite(SinkChannelImpl.java:263)
	at java.base/sun.nio.ch.SinkChannelImpl.write(SinkChannelImpl.java:285)
	at java.base/java.nio.channels.Channels.writeFullyImpl(Channels.java:74)
	at java.base/java.nio.channels.Channels.writeFully(Channels.java:93)
	at java.base/java.nio.channels.Channels$1.write(Channels.java:171)
	at java.base/java.io.OutputStream.write(OutputStream.java:127)
	at java.base/java.nio.channels.Channels$1.write(Channels.java:151)
	at scala.meta.internal.metals.ClosableOutputStream.write(ClosableOutputStream.scala:26)
	at java.base/java.io.FilterOutputStream.write(FilterOutputStream.java:137)
	at java.base/java.io.FilterOutputStream.write(FilterOutputStream.java:108)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:67)
	... 20 more

2024.06.18 14:07:11 INFO  Scala test classes not supported by server
2024.06.18 14:07:11 INFO  Attempting to connect to the build server...
2024.06.18 14:07:11 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 14:07:11 INFO  Attempting to connect to the build server...
2024.06.18 14:07:11 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 14:07:11 INFO  time: Connected to build server in 34ms
2024.06.18 14:07:11 INFO  Connected to Build server: Bloop v1.5.17
2024.06.18 14:07:14 INFO  time: indexed workspace in 3.47s
2024.06.18 14:08:31 INFO  skipping build import with status 'Installed'
2024.06.18 14:08:31 INFO  Disconnecting from Bloop session...
2024.06.18 14:08:31 INFO  Cancelling compilation on Bloop server
2024.06.18 14:08:31 INFO  Shut down connection with build server.
2024.06.18 14:08:31 INFO  no build target found for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/build.sbt. Using presentation compiler with project's scala-library version: 2.12.18
2024.06.18 14:08:31 INFO  Shut down connection with build server.
Jun 18, 2024 2:08:31 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint notify
INFO: Failed to send notification message.
org.eclipse.lsp4j.jsonrpc.JsonRpcException: java.nio.channels.AsynchronousCloseException
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:72)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.notify(RemoteEndpoint.java:126)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.sendCancelNotification(RemoteEndpoint.java:180)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint$1.cancel(RemoteEndpoint.java:150)
	at scala.meta.internal.metals.utils.FutureWithTimeout$$anon$1.$anonfun$cancel$1(FutureWithTimeout.scala:37)
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17)
	at scala.util.Try$.apply(Try.scala:217)
	at scala.meta.internal.metals.utils.FutureWithTimeout$$anon$1.cancel(FutureWithTimeout.scala:37)
	at scala.meta.internal.metals.Cancelable$.$anonfun$cancelAll$1(Cancelable.scala:29)
	at scala.collection.immutable.List.foreach(List.scala:334)
	at scala.meta.internal.metals.Cancelable$.cancelAll(Cancelable.scala:28)
	at scala.meta.internal.metals.MutableCancelable.cancel(MutableCancelable.scala:25)
	at scala.meta.internal.metals.utils.RequestRegistry.cancel(RequestRegistry.scala:94)
	at scala.meta.internal.metals.BuildServerConnection.cancel(BuildServerConnection.scala:447)
	at scala.meta.internal.metals.BuildServerConnection.$anonfun$shutdown$1(BuildServerConnection.scala:179)
	at scala.meta.internal.metals.BuildServerConnection.$anonfun$shutdown$1$adapted(BuildServerConnection.scala:171)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.nio.channels.AsynchronousCloseException
	at java.base/java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)
	at java.base/sun.nio.ch.SinkChannelImpl.endWrite(SinkChannelImpl.java:263)
	at java.base/sun.nio.ch.SinkChannelImpl.write(SinkChannelImpl.java:285)
	at java.base/java.nio.channels.Channels.writeFullyImpl(Channels.java:74)
	at java.base/java.nio.channels.Channels.writeFully(Channels.java:93)
	at java.base/java.nio.channels.Channels$1.write(Channels.java:171)
	at java.base/java.io.OutputStream.write(OutputStream.java:127)
	at java.base/java.nio.channels.Channels$1.write(Channels.java:151)
	at scala.meta.internal.metals.ClosableOutputStream.write(ClosableOutputStream.scala:26)
	at java.base/java.io.FilterOutputStream.write(FilterOutputStream.java:137)
	at java.base/java.io.FilterOutputStream.write(FilterOutputStream.java:108)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:67)
	... 19 more

2024.06.18 14:08:31 INFO  Scala test classes not supported by server
2024.06.18 14:08:31 INFO  Scala main classes not supported by server
2024.06.18 14:08:31 INFO  Attempting to connect to the build server...
2024.06.18 14:08:31 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 14:08:31 INFO  Attempting to connect to the build server...
2024.06.18 14:08:31 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 14:08:31 INFO  time: Connected to build server in 33ms
2024.06.18 14:08:31 INFO  Connected to Build server: Bloop v1.5.17
2024.06.18 14:08:35 INFO  time: indexed workspace in 3.55s
Jun 18, 2024 2:10:32 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.metals/.reports/metals-full/2024-06-18/r_compiler-error_(sparkfinalassignment-build)_14-10-32-184.md
Jun 18, 2024 2:10:35 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.metals/.reports/metals-full/2024-06-18/r_compiler-error_(sparkfinalassignment-build)_14-10-35-441.md
2024.06.18 14:10:35 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/build.sbt
scala.meta.tokenizers.TokenizeException: <input>:27: error: unclosed string interpolation
  --add-opens java.base/java.lang.invoke=ALL-UNNAMED"
                                                     ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:10:49 INFO  running '/opt/homebrew/bin/sbt -Dbloop.export-jar-classifiers=sources bloopInstall'
2024.06.18 14:10:55 INFO  [info] welcome to sbt 1.9.9 (Eclipse Adoptium Java 11.0.23)
2024.06.18 14:10:55 INFO  [info] loading settings for project sparkfinalassignment-build-build from metals.sbt ...
2024.06.18 14:10:55 INFO  [info] loading project definition from /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/project
2024.06.18 14:10:56 INFO  [info] loading settings for project sparkfinalassignment-build from metals.sbt ...
2024.06.18 14:10:56 INFO  [info] loading project definition from /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project
2024.06.18 14:10:56 INFO  [success] Generated .bloop/sparkfinalassignment-build.json
2024.06.18 14:10:56 INFO  [success] Total time: 1 s, completed 18-Jun-2024, 2:10:57 PM
2024.06.18 14:10:58 INFO  [info] loading settings for project sparkfinalassignment from build.sbt ...
2024.06.18 14:10:58 INFO  [info] set current project to LogAnalysis (in build file:/private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/)
2024.06.18 14:11:00 INFO  [success] Generated .bloop/sparkfinalassignment-test.json
2024.06.18 14:11:00 INFO  [success] Generated .bloop/sparkfinalassignment.json
2024.06.18 14:11:00 INFO  [success] Total time: 2 s, completed 18-Jun-2024, 2:11:00 PM
2024.06.18 14:11:00 INFO  time: ran 'sbt bloopInstall' in 11s
2024.06.18 14:11:00 INFO  Disconnecting from Bloop session...
2024.06.18 14:11:00 INFO  Shut down connection with build server.
2024.06.18 14:11:00 INFO  Shut down connection with build server.
2024.06.18 14:11:00 INFO  Attempting to connect to the build server...
2024.06.18 14:11:00 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 14:11:00 INFO  Attempting to connect to the build server...
2024.06.18 14:11:00 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 14:11:00 INFO  time: Connected to build server in 52ms
2024.06.18 14:11:00 INFO  Connected to Build server: Bloop v1.5.17
2024.06.18 14:11:04 INFO  time: indexed workspace in 3.45s
2024.06.18 14:11:04 INFO  skipping build import with status 'Installed'
2024.06.18 14:11:04 INFO  Disconnecting from Bloop session...
2024.06.18 14:11:04 INFO  Shut down connection with build server.
2024.06.18 14:11:04 INFO  Shut down connection with build server.
Jun 18, 2024 2:11:04 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint notify
INFO: Failed to send notification message.
org.eclipse.lsp4j.jsonrpc.JsonRpcException: java.nio.channels.AsynchronousCloseException
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:72)
	at scala.meta.internal.metals.RequestMonitorImpl$$anon$1.consume(ServerLivenessMonitor.scala:41)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.notify(RemoteEndpoint.java:126)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.sendCancelNotification(RemoteEndpoint.java:180)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint$1.cancel(RemoteEndpoint.java:150)
	at scala.meta.internal.metals.utils.FutureWithTimeout$$anon$1.$anonfun$cancel$1(FutureWithTimeout.scala:37)
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17)
	at scala.util.Try$.apply(Try.scala:217)
	at scala.meta.internal.metals.utils.FutureWithTimeout$$anon$1.cancel(FutureWithTimeout.scala:37)
	at scala.meta.internal.metals.Cancelable$.$anonfun$cancelAll$1(Cancelable.scala:29)
	at scala.collection.immutable.List.foreach(List.scala:334)
	at scala.meta.internal.metals.Cancelable$.cancelAll(Cancelable.scala:28)
	at scala.meta.internal.metals.MutableCancelable.cancel(MutableCancelable.scala:25)
	at scala.meta.internal.metals.utils.RequestRegistry.cancel(RequestRegistry.scala:94)
	at scala.meta.internal.metals.BuildServerConnection.cancel(BuildServerConnection.scala:447)
	at scala.meta.internal.metals.BuildServerConnection.$anonfun$shutdown$1(BuildServerConnection.scala:179)
	at scala.meta.internal.metals.BuildServerConnection.$anonfun$shutdown$1$adapted(BuildServerConnection.scala:171)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.nio.channels.AsynchronousCloseException
	at java.base/java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)
	at java.base/sun.nio.ch.SinkChannelImpl.endWrite(SinkChannelImpl.java:263)
	at java.base/sun.nio.ch.SinkChannelImpl.write(SinkChannelImpl.java:285)
	at java.base/java.nio.channels.Channels.writeFullyImpl(Channels.java:74)
	at java.base/java.nio.channels.Channels.writeFully(Channels.java:93)
	at java.base/java.nio.channels.Channels$1.write(Channels.java:171)
	at java.base/java.io.OutputStream.write(OutputStream.java:127)
	at java.base/java.nio.channels.Channels$1.write(Channels.java:151)
	at scala.meta.internal.metals.ClosableOutputStream.write(ClosableOutputStream.scala:26)
	at java.base/java.io.FilterOutputStream.write(FilterOutputStream.java:137)
	at java.base/java.io.FilterOutputStream.write(FilterOutputStream.java:108)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:67)
	... 20 more

2024.06.18 14:11:04 INFO  Scala test classes not supported by server
2024.06.18 14:11:04 INFO  Attempting to connect to the build server...
2024.06.18 14:11:04 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 14:11:04 INFO  Attempting to connect to the build server...
2024.06.18 14:11:04 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 14:11:04 INFO  time: Connected to build server in 43ms
2024.06.18 14:11:04 INFO  Connected to Build server: Bloop v1.5.17
2024.06.18 14:11:07 INFO  time: indexed workspace in 3.41s
2024.06.18 14:12:24 INFO  running '/opt/homebrew/bin/sbt -Dbloop.export-jar-classifiers=sources bloopInstall'
2024.06.18 14:12:30 INFO  [info] welcome to sbt 1.9.9 (Eclipse Adoptium Java 11.0.23)
2024.06.18 14:12:30 INFO  [info] loading settings for project sparkfinalassignment-build-build from metals.sbt ...
2024.06.18 14:12:30 INFO  [info] loading project definition from /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/project
2024.06.18 14:12:31 INFO  [info] loading settings for project sparkfinalassignment-build from metals.sbt ...
2024.06.18 14:12:31 INFO  [info] loading project definition from /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project
2024.06.18 14:12:32 INFO  [success] Generated .bloop/sparkfinalassignment-build.json
2024.06.18 14:12:32 INFO  [success] Total time: 1 s, completed 18-Jun-2024, 2:12:32 PM
2024.06.18 14:12:32 INFO  [info] loading settings for project sparkfinalassignment from build.sbt ...
2024.06.18 14:12:32 INFO  [info] set current project to LogAnalysis (in build file:/private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/)
2024.06.18 14:12:32 INFO  [success] Generated .bloop/sparkfinalassignment.json
2024.06.18 14:12:32 INFO  [success] Generated .bloop/sparkfinalassignment-test.json
2024.06.18 14:12:32 INFO  [success] Total time: 1 s, completed 18-Jun-2024, 2:12:33 PM
2024.06.18 14:12:33 INFO  time: ran 'sbt bloopInstall' in 8.95s
2024.06.18 14:12:33 INFO  Disconnecting from Bloop session...
2024.06.18 14:12:33 INFO  Shut down connection with build server.
2024.06.18 14:12:33 INFO  Shut down connection with build server.
2024.06.18 14:12:33 INFO  Attempting to connect to the build server...
2024.06.18 14:12:33 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 14:12:33 INFO  Attempting to connect to the build server...
2024.06.18 14:12:33 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 14:12:33 INFO  time: Connected to build server in 38ms
2024.06.18 14:12:33 INFO  Connected to Build server: Bloop v1.5.17
2024.06.18 14:12:37 INFO  time: indexed workspace in 3.44s
2024.06.18 14:13:45 INFO  running '/opt/homebrew/bin/sbt -Dbloop.export-jar-classifiers=sources bloopInstall'
2024.06.18 14:13:52 INFO  [info] welcome to sbt 1.9.9 (Eclipse Adoptium Java 11.0.23)
2024.06.18 14:13:52 INFO  [info] loading settings for project sparkfinalassignment-build-build from metals.sbt ...
2024.06.18 14:13:52 INFO  [info] loading project definition from /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/project
2024.06.18 14:13:53 INFO  [info] loading settings for project sparkfinalassignment-build from metals.sbt ...
2024.06.18 14:13:53 INFO  [info] loading project definition from /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project
2024.06.18 14:13:53 INFO  [success] Generated .bloop/sparkfinalassignment-build.json
2024.06.18 14:13:54 INFO  [success] Total time: 1 s, completed 18-Jun-2024, 2:13:54 PM
2024.06.18 14:13:55 INFO  [info] loading settings for project sparkfinalassignment from build.sbt ...
2024.06.18 14:13:55 INFO  [info] set current project to LogAnalysis (in build file:/private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/)
2024.06.18 14:13:55 INFO  [success] Generated .bloop/sparkfinalassignment.json
2024.06.18 14:13:55 INFO  [success] Generated .bloop/sparkfinalassignment-test.json
2024.06.18 14:13:55 INFO  [success] Total time: 1 s, completed 18-Jun-2024, 2:13:56 PM
2024.06.18 14:13:56 INFO  time: ran 'sbt bloopInstall' in 10s
2024.06.18 14:13:56 INFO  Disconnecting from Bloop session...
2024.06.18 14:13:56 INFO  Shut down connection with build server.
2024.06.18 14:13:56 INFO  Shut down connection with build server.
2024.06.18 14:13:56 INFO  Attempting to connect to the build server...
2024.06.18 14:13:56 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 14:13:56 INFO  Attempting to connect to the build server...
2024.06.18 14:13:56 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 14:13:56 INFO  time: Connected to build server in 48ms
2024.06.18 14:13:56 INFO  Connected to Build server: Bloop v1.5.17
2024.06.18 14:13:59 INFO  time: indexed workspace in 3.4s
2024.06.18 14:14:19 INFO  Shutting down server
2024.06.18 14:14:19 INFO  shutting down Metals
2024.06.18 14:14:19 INFO  Shut down connection with build server.
2024.06.18 14:14:19 INFO  Shut down connection with build server.
2024.06.18 14:14:19 INFO  Exiting server
2024.06.18 14:14:27 INFO  Started: Metals version 1.3.1 in folders '/private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment' for client Visual Studio Code 1.89.1.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@2591ab3a]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@3c1ea179]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@2591ab3a]
2024.06.18 14:14:27 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.06.18 14:14:27 INFO  Attempting to connect to the build server...
2024.06.18 14:14:27 INFO  no build target found for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/build.sbt. Using presentation compiler with project's scala-library version: 3.3.3
2024.06.18 14:14:27 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 14:14:27 INFO  Attempting to connect to the build server...
2024.06.18 14:14:27 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 14:14:27 INFO  time: Connected to build server in 0.96s
2024.06.18 14:14:27 INFO  Connected to Build server: Bloop v1.5.17
2024.06.18 14:14:27 WARN  Could not find semantic tokens for: file:///private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/build.sbt
2024.06.18 14:14:38 INFO  time: indexed workspace in 9.6s
2024.06.18 14:14:52 INFO  running '/opt/homebrew/bin/sbt -Dbloop.export-jar-classifiers=sources bloopInstall'
2024.06.18 14:14:58 INFO  [info] welcome to sbt 1.9.9 (Eclipse Adoptium Java 11.0.23)
2024.06.18 14:14:58 INFO  [info] loading settings for project sparkfinalassignment-build-build from metals.sbt ...
2024.06.18 14:14:58 INFO  [info] loading project definition from /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/project
2024.06.18 14:14:59 INFO  [info] loading settings for project sparkfinalassignment-build from metals.sbt ...
2024.06.18 14:14:59 INFO  [info] loading project definition from /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project
2024.06.18 14:14:59 INFO  [success] Generated .bloop/sparkfinalassignment-build.json
2024.06.18 14:15:00 INFO  [success] Total time: 1 s, completed 18-Jun-2024, 2:15:00 PM
2024.06.18 14:15:01 INFO  [info] loading settings for project sparkfinalassignment from build.sbt ...
2024.06.18 14:15:01 INFO  [info] set current project to LogAnalysis (in build file:/private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/)
2024.06.18 14:15:01 INFO  [success] Generated .bloop/sparkfinalassignment.json
2024.06.18 14:15:01 INFO  [success] Generated .bloop/sparkfinalassignment-test.json
2024.06.18 14:15:01 INFO  [success] Total time: 1 s, completed 18-Jun-2024, 2:15:02 PM
2024.06.18 14:15:02 INFO  time: ran 'sbt bloopInstall' in 10s
2024.06.18 14:15:02 INFO  Disconnecting from Bloop session...
2024.06.18 14:15:02 INFO  Shut down connection with build server.
2024.06.18 14:15:02 INFO  Shut down connection with build server.
2024.06.18 14:15:02 INFO  Attempting to connect to the build server...
2024.06.18 14:15:02 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 14:15:02 INFO  Attempting to connect to the build server...
2024.06.18 14:15:02 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 14:15:02 INFO  time: Connected to build server in 64ms
2024.06.18 14:15:02 INFO  Connected to Build server: Bloop v1.5.17
2024.06.18 14:15:06 INFO  time: indexed workspace in 3.47s
2024.06.18 14:15:23 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:15:23 INFO  time: compiled sparkfinalassignment in 0.56s
2024.06.18 14:16:35 INFO  running '/opt/homebrew/bin/sbt -Dbloop.export-jar-classifiers=sources bloopInstall'
2024.06.18 14:16:41 INFO  [info] welcome to sbt 1.9.9 (Eclipse Adoptium Java 11.0.23)
2024.06.18 14:16:41 INFO  [info] loading settings for project sparkfinalassignment-build-build from metals.sbt ...
2024.06.18 14:16:41 INFO  [info] loading project definition from /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/project
2024.06.18 14:16:42 INFO  [info] loading settings for project sparkfinalassignment-build from metals.sbt ...
2024.06.18 14:16:42 INFO  [info] loading project definition from /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project
2024.06.18 14:16:43 INFO  [success] Generated .bloop/sparkfinalassignment-build.json
2024.06.18 14:16:43 INFO  [success] Total time: 1 s, completed 18-Jun-2024, 2:16:43 PM
2024.06.18 14:16:44 INFO  [info] loading settings for project sparkfinalassignment from build.sbt ...
2024.06.18 14:16:44 INFO  [info] set current project to LogAnalysis (in build file:/private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/)
2024.06.18 14:16:44 INFO  [success] Generated .bloop/sparkfinalassignment-test.json
2024.06.18 14:16:44 INFO  [success] Generated .bloop/sparkfinalassignment.json
2024.06.18 14:16:44 INFO  [success] Total time: 1 s, completed 18-Jun-2024, 2:16:45 PM
2024.06.18 14:16:45 INFO  time: ran 'sbt bloopInstall' in 10s
2024.06.18 14:16:45 INFO  Disconnecting from Bloop session...
2024.06.18 14:16:45 INFO  Shut down connection with build server.
2024.06.18 14:16:45 INFO  Shut down connection with build server.
2024.06.18 14:16:45 INFO  Attempting to connect to the build server...
2024.06.18 14:16:45 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 14:16:45 INFO  Attempting to connect to the build server...
2024.06.18 14:16:45 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 14:16:45 INFO  time: Connected to build server in 47ms
2024.06.18 14:16:45 INFO  Connected to Build server: Bloop v1.5.17
2024.06.18 14:16:48 INFO  time: indexed workspace in 3.41s
2024.06.18 14:16:48 INFO  skipping build import with status 'Installed'
2024.06.18 14:16:48 INFO  Disconnecting from Bloop session...
2024.06.18 14:16:48 INFO  Shut down connection with build server.
2024.06.18 14:16:48 INFO  Shut down connection with build server.
Jun 18, 2024 2:16:48 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint notify
INFO: Failed to send notification message.
org.eclipse.lsp4j.jsonrpc.JsonRpcException: java.nio.channels.AsynchronousCloseException
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:72)
	at scala.meta.internal.metals.RequestMonitorImpl$$anon$1.consume(ServerLivenessMonitor.scala:41)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.notify(RemoteEndpoint.java:126)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.sendCancelNotification(RemoteEndpoint.java:180)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint$1.cancel(RemoteEndpoint.java:150)
	at scala.meta.internal.metals.utils.FutureWithTimeout$$anon$1.$anonfun$cancel$1(FutureWithTimeout.scala:37)
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17)
	at scala.util.Try$.apply(Try.scala:217)
	at scala.meta.internal.metals.utils.FutureWithTimeout$$anon$1.cancel(FutureWithTimeout.scala:37)
	at scala.meta.internal.metals.Cancelable$.$anonfun$cancelAll$1(Cancelable.scala:29)
	at scala.collection.immutable.List.foreach(List.scala:334)
	at scala.meta.internal.metals.Cancelable$.cancelAll(Cancelable.scala:28)
	at scala.meta.internal.metals.MutableCancelable.cancel(MutableCancelable.scala:25)
	at scala.meta.internal.metals.utils.RequestRegistry.cancel(RequestRegistry.scala:94)
	at scala.meta.internal.metals.BuildServerConnection.cancel(BuildServerConnection.scala:447)
	at scala.meta.internal.metals.BuildServerConnection.$anonfun$shutdown$1(BuildServerConnection.scala:179)
	at scala.meta.internal.metals.BuildServerConnection.$anonfun$shutdown$1$adapted(BuildServerConnection.scala:171)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.nio.channels.AsynchronousCloseException
	at java.base/java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)
	at java.base/sun.nio.ch.SinkChannelImpl.endWrite(SinkChannelImpl.java:263)
	at java.base/sun.nio.ch.SinkChannelImpl.write(SinkChannelImpl.java:285)
	at java.base/java.nio.channels.Channels.writeFullyImpl(Channels.java:74)
	at java.base/java.nio.channels.Channels.writeFully(Channels.java:93)
	at java.base/java.nio.channels.Channels$1.write(Channels.java:171)
	at java.base/java.io.OutputStream.write(OutputStream.java:127)
	at java.base/java.nio.channels.Channels$1.write(Channels.java:151)
	at scala.meta.internal.metals.ClosableOutputStream.write(ClosableOutputStream.scala:26)
	at java.base/java.io.FilterOutputStream.write(FilterOutputStream.java:137)
	at java.base/java.io.FilterOutputStream.write(FilterOutputStream.java:108)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:67)
	... 20 more

2024.06.18 14:16:48 INFO  Scala test classes not supported by server
2024.06.18 14:16:48 INFO  Attempting to connect to the build server...
2024.06.18 14:16:48 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
Jun 18, 2024 2:16:48 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.metals/.reports/metals-full/2024-06-18/r_compiler-error_(sparkfinalassignment)_14-16-48-971.md
2024.06.18 14:16:48 INFO  Attempting to connect to the build server...
2024.06.18 14:16:48 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 14:16:48 INFO  time: Connected to build server in 38ms
2024.06.18 14:16:48 INFO  Connected to Build server: Bloop v1.5.17
2024.06.18 14:16:52 INFO  time: indexed workspace in 3.45s
Jun 18, 2024 2:18:35 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 432
Jun 18, 2024 2:18:43 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 504
2024.06.18 14:18:48 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:38: error: Not one of: `$$', `$'ident, `$'this, `$'BlockExpr, `$'_
        case e: Exception => println(s"Exception occurred: $")
                                       ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:656)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:19:05 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:19:05 INFO  time: compiled sparkfinalassignment in 0.15s
2024.06.18 14:19:05 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:19:05 INFO  time: compiled sparkfinalassignment in 59ms
2024.06.18 14:19:42 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:19:42 INFO  time: compiled sparkfinalassignment in 0.58s
Jun 18, 2024 2:20:32 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 892
Jun 18, 2024 2:20:33 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 899
2024.06.18 14:21:37 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:21:37 INFO  time: compiled sparkfinalassignment in 0.12s
2024.06.18 14:22:12 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:22:12 INFO  time: compiled sparkfinalassignment in 0.1s
2024.06.18 14:22:12 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:22:12 INFO  time: compiled sparkfinalassignment in 34ms
2024.06.18 14:23:08 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:23:08 INFO  time: compiled sparkfinalassignment in 0.55s
Jun 18, 2024 2:24:09 PM scala.meta.internal.pc.CompletionProvider expected$1
WARNING: offset 1151, count -1, length 1223
2024.06.18 14:26:11 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:26:11 INFO  time: compiled sparkfinalassignment in 0.74s
2024.06.18 14:28:29 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:28:29 INFO  time: compiled sparkfinalassignment in 0.92s
Jun 18, 2024 2:30:42 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1998
Jun 18, 2024 2:30:47 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2042
2024.06.18 14:31:29 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:31:30 INFO  time: compiled sparkfinalassignment in 1.06s
2024.06.18 14:32:15 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:39: error: unclosed string interpolation
    println(s"numOf400s)
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:32:17 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:39: error: unclosed string interpolation
    println(s"numOf400s)
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:32:17 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:39: error: unclosed string interpolation
    println(s"NunumOf400s)
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:32:17 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:39: error: unclosed string interpolation
    println(s"NumbnumOf400s)
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:32:17 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:39: error: unclosed string interpolation
    println(s"Number numOf400s)
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:32:19 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:39: error: unclosed string interpolation
    println(s"Number of numOf400s)
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:32:20 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:39: error: unclosed string interpolation
    println(s"Number of ipdnumOf400s)
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:32:20 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:39: error: unclosed string interpolation
    println(s"Number of ipds wnumOf400s)
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:32:20 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:39: error: unclosed string interpolation
    println(s"Number of ipds wnumOf400s)
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:32:20 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:39: error: unclosed string interpolation
    println(s"Number of ipdnumOf400s)
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:32:21 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:39: error: unclosed string interpolation
    println(s"Number of ipdnumOf400s)
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:32:21 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:39: error: unclosed string interpolation
    println(s"Number of ips numOf400s)
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:32:22 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:39: error: unclosed string interpolation
    println(s"Number of ips wirnumOf400s)
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:32:22 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:39: error: unclosed string interpolation
    println(s"Number of ips wirh numOf400s)
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:32:23 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:39: error: unclosed string interpolation
    println(s"Number of ips winumOf400s)
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:32:24 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:39: error: unclosed string interpolation
    println(s"Number of ips witnumOf400s)
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:32:24 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:39: error: unclosed string interpolation
    println(s"Number of ips with numOf400s)
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:32:25 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:39: error: unclosed string interpolation
    println(s"Number of ips with 4numOf400s)
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:32:27 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:39: error: unclosed string interpolation
    println(s"Number of ips with 4xxnumOf400s)
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:32:28 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:39: error: unclosed string interpolation
    println(s"Number of ips with 4xx stnumOf400s)
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:32:29 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:39: error: unclosed string interpolation
    println(s"Number of ips with 4xx statnumOf400s)
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:32:29 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:39: error: unclosed string interpolation
    println(s"Number of ips with 4xx status numOf400s)
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:32:30 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:39: error: unclosed string interpolation
    println(s"Number of ips with 4xx status:numOf400s)
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

Jun 18, 2024 2:32:31 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2500
2024.06.18 14:32:31 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:39: error: unclosed string interpolation
    println(s"Number of ips with 4xx status: numOf400s)
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:32:32 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:39: error: unclosed string interpolation
    println(s"Number of ips with 4xx status: $numOf400s)
                                                       ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:252)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:32:34 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:39: error: unclosed string literal
    println(s"Number of ips with 4xx status: $numOf400s"")
                                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:32:37 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:32:37 INFO  time: compiled sparkfinalassignment in 0.9s
Jun 18, 2024 2:33:34 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2596
2024.06.18 14:34:33 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: Not one of: `$$', `$'ident, `$'this, `$'BlockExpr, `$'_
    println(s"Number of requests with more than 5000 bytes as response: $")
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:656)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:34:49 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:34:49 INFO  time: compiled sparkfinalassignment in 0.26s
2024.06.18 14:35:14 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:35:14 INFO  time: compiled sparkfinalassignment in 0.83s
2024.06.18 14:36:27 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:36:27 INFO  time: compiled sparkfinalassignment in 0.83s
2024.06.18 14:39:12 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:39:12 INFO  time: compiled sparkfinalassignment in 0.82s
Jun 18, 2024 2:39:20 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3492
2024.06.18 14:39:49 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:39:51 INFO  time: compiled sparkfinalassignment in 1.58s
2024.06.18 14:40:23 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:40:23 INFO  time: compiled sparkfinalassignment in 0.58s
Jun 18, 2024 2:43:41 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3786
Jun 18, 2024 2:43:56 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3943
2024.06.18 14:44:02 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:44:02 INFO  time: compiled sparkfinalassignment in 0.63s
2024.06.18 14:44:53 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:44:53 INFO  time: compiled sparkfinalassignment in 0.64s
2024.06.18 14:45:58 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:45:58 INFO  time: compiled sparkfinalassignment in 0.61s
2024.06.18 14:46:01 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:46:01 INFO  time: compiled sparkfinalassignment in 0.59s
2024.06.18 14:46:49 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:46:49 INFO  time: compiled sparkfinalassignment in 0.66s
2024.06.18 14:47:30 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:47:30 INFO  time: compiled sparkfinalassignment in 0.82s
2024.06.18 14:47:43 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:47:43 INFO  time: compiled sparkfinalassignment in 0.51s
2024.06.18 14:48:29 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:47: error: Not one of: `$$', `$'ident, `$'this, `$'BlockExpr, `$'_
    print(s"Request with more hits: $")
            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:656)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:48:47 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:47: error: Not one of: `$$', `$'ident, `$'this, `$'BlockExpr, `$'_
    print(s"Request with more hits: $requestsWithMoreHits(0) with hits $")
                                                         ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:656)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:252)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:48:48 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:47: error: Not one of: `$$', `$'ident, `$'this, `$'BlockExpr, `$'_
    print(s"Request with more hits: $requestsWithMoreHits(0) with hits $.takeOrdered(1)(Ordering[Int].reverse.on(_._2))")
                                                         ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:656)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:252)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:48:50 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:47: error: Not one of: `$$', `$'ident, `$'this, `$'BlockExpr, `$'_
    print(s"Request with more hits: $requestsWithMoreHits(0) with hits $")
                                                         ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:656)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:252)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:48:55 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:48:55 INFO  time: compiled sparkfinalassignment in 0.61s
2024.06.18 14:49:55 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:49:55 INFO  time: compiled sparkfinalassignment in 0.61s
Jun 18, 2024 2:51:00 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4891
Jun 18, 2024 2:51:54 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5265
2024.06.18 14:52:16 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:55: error: can't use unescaped LF in character literals
    re'
       ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:390)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:52:40 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:52:40 INFO  time: compiled sparkfinalassignment in 0.59s
2024.06.18 14:54:05 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:49: error: Not one of: `$$', `$'ident, `$'this, `$'BlockExpr, `$'_
    println(s"Request with more hits: $")
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:656)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:54:19 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:49: error: Not one of: `$$', `$'ident, `$'this, `$'BlockExpr, `$'_
    println(s"Request with more hits: ${requestWithMoreHits._1} with $")
                                                               ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:656)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:252)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:54:41 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:51: error: Not one of: `$$', `$'ident, `$'this, `$'BlockExpr, `$'_
    print(s"Request with more 404 response: $")
            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:656)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:54:56 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:51: error: Not one of: `$$', `$'ident, `$'this, `$'BlockExpr, `$'_
    print(s"Request with more 404 response: ${requestWithMore404._1} with number $")
                                                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:656)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:252)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:55:06 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:55:06 INFO  time: compiled sparkfinalassignment in 0.2s
2024.06.18 14:55:06 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:55:06 INFO  time: compiled sparkfinalassignment in 77ms
2024.06.18 14:55:06 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:55:06 INFO  time: compiled sparkfinalassignment in 72ms
2024.06.18 14:55:09 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:55:09 INFO  time: compiled sparkfinalassignment in 0.14s
2024.06.18 14:55:09 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:55:09 INFO  time: compiled sparkfinalassignment in 67ms
2024.06.18 14:55:58 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:51: error: unclosed string interpolation
    print(s"Request with more 404 response: ${requestWithMore404._1} with number ${requestWithMore404._2")
                                                                                                         ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:56:03 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:51: error: unclosed string interpolation
    print(s"Request with more 404 response: ${requestWithMore404._1 with number $requestWithMore404._2")
                                                                                                       ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:56:07 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:56:07 INFO  time: compiled sparkfinalassignment in 0.55s
2024.06.18 14:57:02 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:49: error: unclosed string interpolation
    println(s"Request with more hits: ${requestWithMoreHits._1 with $requestWithMoreHits._2 hits")
                                                                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:57:10 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:49: error: unclosed string interpolation
    println(s"Request with more hits: ${requestWithMoreHits._1} with ${requestWithMoreHits._2 hits")
                                                                                                   ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:57:16 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:57:16 INFO  time: compiled sparkfinalassignment in 0.18s
2024.06.18 14:57:16 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:57:16 INFO  time: compiled sparkfinalassignment in 70ms
2024.06.18 14:57:16 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:57:16 INFO  time: compiled sparkfinalassignment in 75ms
2024.06.18 14:57:16 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:57:16 INFO  time: compiled sparkfinalassignment in 64ms
2024.06.18 14:57:16 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:57:16 INFO  time: compiled sparkfinalassignment in 65ms
2024.06.18 14:57:16 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:57:16 INFO  time: compiled sparkfinalassignment in 64ms
2024.06.18 14:57:38 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:51: error: unclosed string interpolation
    println(s"Request with more 404 response: ${requestWithMore404._1 with number $requestWithMore404._2")
                                                                                                         ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:57:45 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:51: error: unclosed string interpolation
    println(s"Request with more 404 response: ${requestWithMore404._1} with number ${requestWithMore404._2")
                                                                                                           ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

Jun 18, 2024 2:57:46 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 6384
2024.06.18 14:57:49 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:57:49 INFO  time: compiled sparkfinalassignment in 0.14s
2024.06.18 14:57:49 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:57:49 INFO  time: compiled sparkfinalassignment in 61ms
2024.06.18 14:57:49 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:57:49 INFO  time: compiled sparkfinalassignment in 72ms
2024.06.18 14:57:49 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:57:49 INFO  time: compiled sparkfinalassignment in 63ms
2024.06.18 14:57:49 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:57:49 INFO  time: compiled sparkfinalassignment in 78ms
2024.06.18 14:57:49 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:57:49 INFO  time: compiled sparkfinalassignment in 64ms
2024.06.18 14:57:49 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:57:50 INFO  time: compiled sparkfinalassignment in 63ms
2024.06.18 14:57:50 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:57:50 INFO  time: compiled sparkfinalassignment in 74ms
2024.06.18 14:58:29 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:58:29 INFO  time: compiled sparkfinalassignment in 0.14s
2024.06.18 14:58:29 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:58:29 INFO  time: compiled sparkfinalassignment in 70ms
2024.06.18 14:58:29 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:58:29 INFO  time: compiled sparkfinalassignment in 64ms
2024.06.18 14:58:29 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:58:29 INFO  time: compiled sparkfinalassignment in 75ms
2024.06.18 14:58:29 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:58:29 INFO  time: compiled sparkfinalassignment in 67ms
2024.06.18 14:58:29 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:58:29 INFO  time: compiled sparkfinalassignment in 68ms
2024.06.18 14:58:30 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:58:30 INFO  time: compiled sparkfinalassignment in 65ms
2024.06.18 14:58:30 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:58:30 INFO  time: compiled sparkfinalassignment in 62ms
2024.06.18 14:59:05 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:49: error: unclosed string interpolation
    println(s"Request with more hits: )
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:59:05 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:49: error: unclosed string interpolation
    println(s"Request with more hits:)
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:59:06 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:49: error: unclosed string interpolation
    println(s"Request with more hits: )
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:666)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:364)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:59:06 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:49: error: unclosed string literal
    println(s"Request with more hits: "")
                                       ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 14:59:43 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 14:59:43 INFO  time: compiled sparkfinalassignment in 0.55s
2024.06.18 15:01:18 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 15:01:18 INFO  time: compiled sparkfinalassignment in 0.2s
2024.06.18 15:01:18 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 15:01:18 INFO  time: compiled sparkfinalassignment in 43ms
2024.06.18 15:01:18 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 15:01:18 INFO  time: compiled sparkfinalassignment in 36ms
2024.06.18 15:01:18 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 15:01:18 INFO  time: compiled sparkfinalassignment in 44ms
Jun 18, 2024 3:02:28 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 7146
something's wrong: no file:///private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala in Array[<error>]RangePosition(file:///private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala, 414, 414, 429)
2024.06.18 15:03:17 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional1.scala
scala.meta.tokenizers.TokenizeException: <input>:19: error: unclosed quoted identifier
    `val spark = SparkSession
    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getBackquotedIdent(LegacyScanner.scala:496)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:344)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 15:04:21 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 15:04:21 INFO  time: compiled sparkfinalassignment in 0.11s
2024.06.18 15:04:32 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 15:04:32 INFO  time: compiled sparkfinalassignment in 0.64s
2024.06.18 15:12:48 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 15:12:48 INFO  time: compiled sparkfinalassignment in 0.24s
2024.06.18 15:13:03 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 15:13:03 INFO  time: compiled sparkfinalassignment in 0.58s
Jun 18, 2024 3:15:06 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 8083
Jun 18, 2024 3:15:13 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 8119
something's wrong: no file:///private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional2.scala in Array[<error>]RangePosition(file:///private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional2.scala, 350, 350, 365)
something's wrong: no file:///private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional2.scala in Array[<error>]RangePosition(file:///private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional2.scala, 350, 350, 358)
something's wrong: no file:///private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional2.scala in Array[<error>]RangePosition(file:///private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional2.scala, 350, 350, 359)
something's wrong: no file:///private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional2.scala in Array[String]RangePosition(file:///private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional2.scala, 350, 350, 363)
Jun 18, 2024 3:15:30 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 8277
Jun 18, 2024 3:15:34 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 8293
Jun 18, 2024 3:44:09 PM scala.meta.internal.pc.CompilerAccess retryWithCleanCompiler
INFO: compiler crashed due to an error in the Scala compiler, retrying with new compiler instance.
Jun 18, 2024 3:44:10 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.metals/.reports/metals-full/2024-06-18/r_compiler-error_(sparkfinalassignment)_15-44-10-013.md
Jun 18, 2024 3:44:16 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 8514
Jun 18, 2024 3:45:19 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 9028
2024.06.18 15:46:21 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 15:46:21 INFO  time: compiled sparkfinalassignment in 0.48s
2024.06.18 15:46:24 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 15:46:24 INFO  time: compiled sparkfinalassignment in 0.37s
2024.06.18 15:46:38 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 15:46:38 INFO  time: compiled sparkfinalassignment in 0.35s
Jun 18, 2024 4:12:22 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 9611
Jun 18, 2024 4:12:38 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 9704
Jun 18, 2024 4:13:15 PM scala.meta.internal.pc.CompletionProvider expected$1
WARNING: offset 896, count -1, length 935
2024.06.18 16:13:40 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 16:13:40 INFO  time: compiled sparkfinalassignment in 0.45s
Jun 18, 2024 4:14:59 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 10191
Jun 18, 2024 4:15:06 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 10252
Jun 18, 2024 4:15:28 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 10337
2024.06.18 16:15:32 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional2.scala
scala.meta.tokenizers.TokenizeException: <input>:34: error: unclosed character literal
        val authorsDf = booksSalesDf.select("author_id", 'auth')
                                                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

Jun 18, 2024 4:15:32 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 10367
2024.06.18 16:15:32 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional2.scala
scala.meta.tokenizers.TokenizeException: <input>:34: error: unclosed character literal
        val authorsDf = booksSalesDf.select("author_id", 'author')
                                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 16:15:33 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional2.scala
scala.meta.tokenizers.TokenizeException: <input>:34: error: unclosed character literal
        val authorsDf = booksSalesDf.select("author_id", 'auth')
                                                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 16:15:33 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional2.scala
scala.meta.tokenizers.TokenizeException: <input>:34: error: unclosed character literal
        val authorsDf = booksSalesDf.select("author_id", 'au')
                                                            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 16:15:33 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional2.scala
scala.meta.tokenizers.TokenizeException: <input>:34: error: unclosed character literal
        val authorsDf = booksSalesDf.select("author_id", '')
                                                         ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:414)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:419)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 16:15:57 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 16:15:57 INFO  time: compiled sparkfinalassignment in 0.49s
Jun 18, 2024 4:18:41 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 10678
Jun 18, 2024 4:19:10 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 10833
Jun 18, 2024 4:19:35 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 10999
2024.06.18 16:19:51 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 16:19:52 INFO  time: compiled sparkfinalassignment in 1.09s
2024.06.18 16:29:54 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 16:29:54 INFO  time: compiled sparkfinalassignment in 0.16s
2024.06.18 16:30:51 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 16:30:51 INFO  time: compiled sparkfinalassignment in 0.13s
Jun 18, 2024 4:31:15 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 11711
2024.06.18 16:32:28 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 16:32:28 INFO  time: compiled sparkfinalassignment in 0.14s
2024.06.18 16:32:28 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 16:32:28 INFO  time: compiled sparkfinalassignment in 51ms
2024.06.18 16:32:34 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 16:32:34 INFO  time: compiled sparkfinalassignment in 0.15s
2024.06.18 16:34:11 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 16:34:11 INFO  time: compiled sparkfinalassignment in 0.42s
Jun 18, 2024 4:34:24 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 11914
2024.06.18 16:34:27 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 16:34:27 INFO  time: compiled sparkfinalassignment in 0.38s
Jun 18, 2024 4:38:52 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 12156
Jun 18, 2024 4:39:22 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 12283
2024.06.18 16:39:42 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 16:39:42 INFO  time: compiled sparkfinalassignment in 0.13s
2024.06.18 16:40:16 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional2.scala
scala.meta.tokenizers.TokenizeException: <input>:46: error: unclosed string literal
        val salesByMonthDf = booksSalesDf.withColumn("month", booksSalesDf("sale_d)
                                                                           ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 16:40:17 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional2.scala
scala.meta.tokenizers.TokenizeException: <input>:46: error: unclosed string literal
        val salesByMonthDf = booksSalesDf.withColumn("month", booksSalesDf("sa)
                                                                           ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 16:40:38 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 16:40:38 INFO  time: compiled sparkfinalassignment in 0.14s
2024.06.18 16:40:55 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional2.scala
scala.meta.tokenizers.TokenizeException: <input>:46: error: unclosed string literal
        val salesByMonthDf = booksSalesDf.withColumn("month", to_date(col("sale_month")).split("-)
                                                                                               ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 16:41:01 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 16:41:01 INFO  time: compiled sparkfinalassignment in 0.4s
Jun 18, 2024 4:43:33 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 13018
2024.06.18 16:43:52 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 16:43:52 INFO  time: compiled sparkfinalassignment in 0.42s
2024.06.18 16:46:20 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 16:46:20 INFO  time: compiled sparkfinalassignment in 0.49s
2024.06.18 16:47:27 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 16:47:27 INFO  time: compiled sparkfinalassignment in 0.41s
Jun 18, 2024 4:49:16 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 14252
2024.06.18 16:49:30 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 16:49:30 INFO  time: compiled sparkfinalassignment in 0.46s
Jun 18, 2024 4:50:37 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 14402
2024.06.18 16:52:30 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 16:52:30 INFO  time: compiled sparkfinalassignment in 0.41s
Jun 18, 2024 4:52:43 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 14999
Jun 18, 2024 4:52:48 PM scala.meta.internal.pc.CompilerAccess retryWithCleanCompiler
INFO: compiler crashed due to an error in the Scala compiler, retrying with new compiler instance.
Jun 18, 2024 4:52:48 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.metals/.reports/metals-full/2024-06-18/r_compiler-error_(sparkfinalassignment)_16-52-48-837.md
2024.06.18 16:54:34 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 16:54:34 INFO  time: compiled sparkfinalassignment in 0.38s
Jun 18, 2024 4:55:56 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 15948
Jun 18, 2024 5:00:14 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 16561
2024.06.18 17:01:10 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional2.scala
scala.meta.tokenizers.TokenizeException: <input>:77: error: unclosed string literal
        writeDataFrameToDb(salesByTitlesDf, "\")
                                            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.18 17:01:47 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 17:01:47 INFO  time: compiled sparkfinalassignment in 0.2s
2024.06.18 17:02:05 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.18 17:02:05 INFO  time: compiled sparkfinalassignment in 0.44s
2024.06.18 17:08:35 INFO  running '/opt/homebrew/bin/sbt -Dbloop.export-jar-classifiers=sources bloopInstall'
2024.06.18 17:08:41 INFO  [info] welcome to sbt 1.9.9 (Eclipse Adoptium Java 11.0.23)
2024.06.18 17:08:41 INFO  [info] loading settings for project sparkfinalassignment-build-build from metals.sbt ...
2024.06.18 17:08:41 INFO  [info] loading project definition from /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/project
2024.06.18 17:08:42 INFO  [info] loading settings for project sparkfinalassignment-build from metals.sbt ...
2024.06.18 17:08:42 INFO  [info] loading project definition from /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project
2024.06.18 17:08:42 INFO  [success] Generated .bloop/sparkfinalassignment-build.json
2024.06.18 17:08:42 INFO  [success] Total time: 1 s, completed 18-Jun-2024, 5:08:43 PM
2024.06.18 17:08:44 INFO  [info] loading settings for project sparkfinalassignment from build.sbt ...
2024.06.18 17:08:44 INFO  [info] set current project to LogAnalysis (in build file:/private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/)
2024.06.18 17:08:47 INFO  [success] Generated .bloop/sparkfinalassignment-test.json
2024.06.18 17:08:47 INFO  [success] Generated .bloop/sparkfinalassignment.json
2024.06.18 17:08:47 INFO  [success] Total time: 2 s, completed 18-Jun-2024, 5:08:47 PM
2024.06.18 17:08:47 INFO  time: ran 'sbt bloopInstall' in 11s
2024.06.18 17:08:47 INFO  Disconnecting from Bloop session...
2024.06.18 17:08:47 INFO  Shut down connection with build server.
2024.06.18 17:08:47 INFO  Shut down connection with build server.
2024.06.18 17:08:47 INFO  Attempting to connect to the build server...
2024.06.18 17:08:47 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 17:08:47 INFO  Attempting to connect to the build server...
2024.06.18 17:08:47 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 17:08:47 INFO  time: Connected to build server in 64ms
2024.06.18 17:08:47 INFO  Connected to Build server: Bloop v1.5.17
2024.06.18 17:08:51 INFO  time: indexed workspace in 4.04s
2024.06.18 17:08:51 INFO  compiling sparkfinalassignment (2 scala sources)
2024.06.18 17:08:51 INFO  time: compiled sparkfinalassignment in 0.72s
2024.06.18 17:08:52 INFO  skipping build import with status 'Installed'
2024.06.18 17:08:52 INFO  Disconnecting from Bloop session...
2024.06.18 17:08:52 INFO  Shut down connection with build server.
2024.06.18 17:08:52 INFO  Shut down connection with build server.
Jun 18, 2024 5:08:52 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint notify
INFO: Failed to send notification message.
org.eclipse.lsp4j.jsonrpc.JsonRpcException: java.nio.channels.AsynchronousCloseException
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:72)
	at scala.meta.internal.metals.RequestMonitorImpl$$anon$1.consume(ServerLivenessMonitor.scala:41)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.notify(RemoteEndpoint.java:126)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.sendCancelNotification(RemoteEndpoint.java:180)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint$1.cancel(RemoteEndpoint.java:150)
	at scala.meta.internal.metals.utils.FutureWithTimeout$$anon$1.$anonfun$cancel$1(FutureWithTimeout.scala:37)
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.scala:17)
	at scala.util.Try$.apply(Try.scala:217)
	at scala.meta.internal.metals.utils.FutureWithTimeout$$anon$1.cancel(FutureWithTimeout.scala:37)
	at scala.meta.internal.metals.Cancelable$.$anonfun$cancelAll$1(Cancelable.scala:29)
	at scala.collection.immutable.List.foreach(List.scala:334)
	at scala.meta.internal.metals.Cancelable$.cancelAll(Cancelable.scala:28)
	at scala.meta.internal.metals.MutableCancelable.cancel(MutableCancelable.scala:25)
	at scala.meta.internal.metals.utils.RequestRegistry.cancel(RequestRegistry.scala:94)
	at scala.meta.internal.metals.BuildServerConnection.cancel(BuildServerConnection.scala:447)
	at scala.meta.internal.metals.BuildServerConnection.$anonfun$shutdown$1(BuildServerConnection.scala:179)
	at scala.meta.internal.metals.BuildServerConnection.$anonfun$shutdown$1$adapted(BuildServerConnection.scala:171)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.nio.channels.AsynchronousCloseException
	at java.base/java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)
	at java.base/sun.nio.ch.SinkChannelImpl.endWrite(SinkChannelImpl.java:263)
	at java.base/sun.nio.ch.SinkChannelImpl.write(SinkChannelImpl.java:285)
	at java.base/java.nio.channels.Channels.writeFullyImpl(Channels.java:74)
	at java.base/java.nio.channels.Channels.writeFully(Channels.java:93)
	at java.base/java.nio.channels.Channels$1.write(Channels.java:171)
	at java.base/java.io.OutputStream.write(OutputStream.java:127)
	at java.base/java.nio.channels.Channels$1.write(Channels.java:151)
	at scala.meta.internal.metals.ClosableOutputStream.write(ClosableOutputStream.scala:26)
	at java.base/java.io.FilterOutputStream.write(FilterOutputStream.java:137)
	at java.base/java.io.FilterOutputStream.write(FilterOutputStream.java:108)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:67)
	... 20 more

2024.06.18 17:08:52 INFO  Scala test classes not supported by server
2024.06.18 17:08:52 INFO  Attempting to connect to the build server...
2024.06.18 17:08:52 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 17:08:52 INFO  Attempting to connect to the build server...
2024.06.18 17:08:52 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.18 17:08:52 INFO  time: Connected to build server in 33ms
2024.06.18 17:08:52 INFO  Connected to Build server: Bloop v1.5.17
2024.06.18 17:08:55 INFO  time: indexed workspace in 3.48s
2024.06.18 20:02:39 INFO  Shutting down server
2024.06.18 20:02:39 INFO  shutting down Metals
2024.06.18 20:02:39 INFO  Shut down connection with build server.
2024.06.18 20:02:39 INFO  Shut down connection with build server.
2024.06.18 20:02:39 INFO  Exiting server
2024.06.19 08:59:50 INFO  Started: Metals version 1.3.1 in folders '/private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment' for client Visual Studio Code 1.89.1.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@5c576569]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@74b7cda2]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@5c576569]
2024.06.19 08:59:50 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.06.19 08:59:50 INFO  Attempting to connect to the build server...
2024.06.19 08:59:50 INFO  no build target found for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional2.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.06.19 08:59:51 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.19 08:59:51 INFO  Attempting to connect to the build server...
2024.06.19 08:59:51 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.19 08:59:51 INFO  time: Connected to build server in 0.45s
2024.06.19 08:59:51 INFO  Connected to Build server: Bloop v1.5.17
2024.06.19 08:59:55 INFO  time: indexed workspace in 4.54s
2024.06.19 09:02:39 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.19 09:02:39 INFO  time: compiled sparkfinalassignment in 0.62s
2024.06.19 09:06:37 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.19 09:06:37 INFO  time: compiled sparkfinalassignment in 0.62s
2024.06.19 09:12:28 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.19 09:12:28 INFO  time: compiled sparkfinalassignment in 0.58s
2024.06.19 09:14:25 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.19 09:14:25 INFO  time: compiled sparkfinalassignment in 0.96s
2024.06.19 09:17:09 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.06.19 09:17:09 INFO  no build target found for /scala/Tuple4.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.06.19 09:17:09 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.19 09:17:09 INFO  time: compiled sparkfinalassignment in 0.67s
2024.06.19 09:19:04 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.19 09:19:04 INFO  time: compiled sparkfinalassignment in 0.58s
2024.06.19 09:22:33 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.19 09:22:33 INFO  time: compiled sparkfinalassignment in 0.51s
2024.06.19 10:16:11 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.19 10:16:11 INFO  time: compiled sparkfinalassignment in 0.96s
2024.06.19 10:16:42 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional2.scala
scala.meta.tokenizers.TokenizeException: <input>:35: error: unclosed string literal
        .option("password", "Password@131299)
                            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.19 10:16:43 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional2.scala
scala.meta.tokenizers.TokenizeException: <input>:35: error: unclosed string literal
        .option("password", "Password@13)
                            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.19 10:16:43 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional2.scala
scala.meta.tokenizers.TokenizeException: <input>:35: error: unclosed string literal
        .option("password", "Passwor)
                            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

2024.06.19 10:16:43 ERROR Failed to tokenize input for semantic tokens for /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/src/main/scala/SparkOptional2.scala
scala.meta.tokenizers.TokenizeException: <input>:35: error: unclosed string literal
        .option("password", "Pas)
                            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:560)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:379)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:383)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:214)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:982)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:16)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:16)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:331)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:30)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:514)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:833)

Jun 19, 2024 10:16:52 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1499
2024.06.19 10:17:01 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.19 10:17:01 INFO  time: compiled sparkfinalassignment in 0.3s
2024.06.19 10:17:01 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.19 10:17:01 INFO  time: compiled sparkfinalassignment in 0.11s
2024.06.19 10:17:01 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.19 10:17:01 INFO  time: compiled sparkfinalassignment in 0.1s
2024.06.19 10:18:13 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.19 10:18:13 INFO  time: compiled sparkfinalassignment in 0.82s
2024.06.19 10:18:23 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.19 10:18:23 INFO  time: compiled sparkfinalassignment in 0.26s
2024.06.19 10:18:54 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.19 10:18:54 INFO  time: compiled sparkfinalassignment in 0.83s
2024.06.19 10:21:55 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.19 10:21:55 INFO  time: compiled sparkfinalassignment in 0.52s
2024.06.19 10:39:39 INFO  compiling sparkfinalassignment (1 scala source)
2024.06.19 10:39:39 INFO  time: compiled sparkfinalassignment in 0.54s
Jun 19, 2024 11:02:39 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2102
Jun 19, 2024 11:29:47 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2166
2024.06.19 21:46:39 INFO  Shutting down server
2024.06.19 21:46:39 INFO  shutting down Metals
2024.06.19 21:46:39 INFO  Shut down connection with build server.
2024.06.19 21:46:39 INFO  Shut down connection with build server.
2024.06.19 21:46:39 INFO  Exiting server
2024.06.19 21:47:15 INFO  Started: Metals version 1.3.2 in folders '/private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment' for client Visual Studio Code 1.89.1.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@6f5fb9cc]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@4a9b0a42]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@6f5fb9cc]
2024.06.19 21:47:15 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.06.19 21:47:15 INFO  Attempting to connect to the build server...
2024.06.19 21:47:16 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
Jun 19, 2024 9:47:16 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3
Jun 19, 2024 9:47:16 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2
Jun 19, 2024 9:47:16 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1
2024.06.19 21:47:20 INFO  Attempting to connect to the build server...
2024.06.19 21:47:20 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /private/var/folders/1d/_0pnt2994vg5xvvvj4fk41qr0000gp/T/sparkfinalassignment/project/.metals/bsp.trace.json or /Users/srinadh/Library/Caches/org.scalameta.metals/bsp.trace.json
2024.06.19 21:47:20 INFO  time: Connected to build server in 4.14s
2024.06.19 21:47:20 INFO  Connected to Build server: Bloop v1.5.17
2024.06.19 21:47:34 INFO  time: indexed workspace in 14s
2024.06.19 21:47:34 INFO  compiling sparkfinalassignment (2 scala sources)
2024.06.19 21:47:35 INFO  time: compiled sparkfinalassignment in 1.21s
